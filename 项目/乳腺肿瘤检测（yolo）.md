## 乳腺肿瘤检测（深度学习）



#### 1.不理解的概念

- **特征点检测：**特征点检测是指在图像中寻找具有独特性质和可重复性的关键点。这些关键点通常是在图像中**具有显著变化的区域**，例**如边缘、角点**等。特征点检测的目标是找到图像中具代表性的关键点，以便在后续的图像处理和分析中使用。

- **SVM**：支持向量器，是一种二类分类模型，他的基本模型是定义在特征空间上的**间隔最大**的线性分类器，SVM的学习策略就是间隔最大化。对于支持向量机来说，数据点若是n维向量，我们用n−1维的超平面来分开这些点。但是可能有许多超平面可以把数据分类。最佳超平面的一个合理选择就是以最大间隔把两个类分开的超平面。因此，SVM选择最佳超平面。

  ![image-20231101172949996](/Users/lifangyuan/Desktop/learn/pic/image-20231101172949996.png)

- **随机森林**：当我们进行分类任务时，新的输入样本进入，就让森林中的每一棵决策树分别进行判断和分类，每个决策树会得到一个自己的分类结果，决策树的分类结果中哪一个分类最多，那么随机森林就会把这个结果当做最终的结果。

- **逻辑回归：**先用线性拟合，然后对线性拟合的预测结果值进行量化，即将连续值量化为离散值——即**使用『线性回归+阈值』解决分类问题**。因为「线性回归+阈值」的方式很难得到鲁棒性好的分类器，我们对其进行拓展得到鲁棒性更好的逻辑回归（ Logistic Regression，有些地方也叫做「对数几率回归」）。逻辑回归将数据拟合到一个logit函数中，从而完成对事件发生概率的预测。

- **多尺度滑动窗口法**：当前的人体检测技术基本都会采用到多尺度滑动窗口法，该方法需要**对图像做不同尺度的缩放**，然后**用固定大小的滑动窗口以等距步长在整幅图像上滑动，并对每一个滑动窗口做人体检测**。

  

  ![image-20231101220526193](/Users/lifangyuan/Desktop/learn/pic/image-20231101220526193.png)

- 图像分类 & 目标检测 & 图像分割 & 语义分割

  图像分类：输入一张图像，计算机能告诉我们图像中有什么类别（并不知道这个类别在图像中的位置），只是输出txt

  目标检测：输入一张图像，计算机用矩形框 框出各个物体，并识别出各个物体的类别

  图像分割：分为语义分割和实例分割。语义分割是输入一张图像，计算机用抠图级别的 扣出各个物体，并识别各个物体的类别。：

  实例分割：输入一张图像，计算机用抠图级别的 扣出各个物体，并识别该类别里的各个实例。

  ![image-20231103172959418](/Users/lifangyuan/Desktop/learn/pic/image-20231103172959418.png)



#### 2.传统目标检测

1. 选定目标区域
   - 一般用多尺度滑动窗口，不容易漏掉目标
2. 提取目标特征
   - 利用目标区域的抗形变和表达能力的特性进行特征提取，便于分类
3. 分类
   - 用事先准备好的分类器进行分类，如SVM，随机森林，逻辑回归



#### 3.深度学习目标检测

根据是否生成候选区域，分为一阶段目标检测算法和二阶段目标检测算法

1. 一阶段目标检测算法

   一阶段目标检测算法只有检测过程, 无需框定候选区域, 常见算法包括 YOLO 系列（YOLOv1–YOLOv5最具有代表性）、SSD和 RetinaNet 等.

2. 二阶段目标检测算法

   二阶段目标检测算法分为两个阶段, 先框定候选区域, 再进行检测, 常见算法包括 R-CNN、SPPNet、Fast R-CNN和 Faster R-CNN 等; 



#### 4.YOLO v1

训练与预测阶段

- **预测阶段（前向推端，预测图片）**

  - **过程**

    模型训练完之后，是一个深度卷积神经网络。

    

    输入448 * 448 * 3的一个图像，（图片缩放为448 * 448 * 3，rgb）；

    过卷积层（1 * 1，3 * 3）、池化层；最后变成一个7 * 7 * 1024维的feature map，

    把 7 * 7 * 1024维的拉平 ，喂到一个4096个神经元的全连接层中，输出4096维的向量，

    再把4096维的向量喂到一个1470个神经元的全连接层中，输出1470维的向量，

    再把1470个数字reshape成7 * 7 * 30的feature map。

    （输入448 * 448 * 3的图像，输出是7 * 7 * 30的张量）

    ![image-20231105133507180](/Users/lifangyuan/Desktop/learn/pic/image-20231105133507180.png)

    

  - **如何解析 7 * 7 * 30的张量**

    在7 * 7 * 30的张量中包含了所有预测框的坐标，置信度（置信度为边界框与真实框的交并比）和类别结果（只需要解析 7 * 7 * 30维的张量就可以解析最终目标检测的结果了）

    

    那么为什么是 7 * 7 * 30呢，首先把图像划分成S * S个grid cell（网格），yolov1中S = 7 ，所以是7 * 7的网格，那么图像就被划分成了49个grid cell；

    

    每个grid cell又能预测出B个bounding box（预测框），yolov1中B = 2，就是每个grid cell预测出两个预测框，这两个预测框的中心点都会落在生成他俩的grid cell的内部，每个预测框又包括x、y、w、h四个定位坐标，（xy是预测框中心点的坐标，wh是预测框的宽高），由这四个坐标就可以确定预测框的位置，以及包含这个预测框框住的区域是否是一个物体的置信度，在图像中用预测框的线条粗细来表示置信度（粗的表示置信度高，细的表示置信度低）；

    

    那么一个图像有49个grid cell，每个grid cell又有两个bounding box，那么每个图像就会生成98个bounding box，每个bounding box都包含四个未知参数和一个置信度参数（可视化出来 图）

    

    每个grid cell除了生成两个预测框，还会生成所有类别的条件概率（假设它包含物体的情况下，是这个类别的概率），把每个bounding box的置信度乘以每个类别的条件概率就能获得每个bounding box的各类别的概率，结合bounding box的信息和该grid cell的类别信息就可以获得预测结果了。最后通过计算，每个grid cell会选中一个置信度较高的bounding box进行框选物体，并且该物体的类别选择为20个类别中概率最高的，也就是说每个grid cell只能预测出一个类别，那么49个grid cell最多预测出49个类别。

    

    输出1个图像 输出7 * 7 * 3 0的张量，7 * 7就是 该图像被分成了49个grid cell，30就是两个预测框，每个预测框有5个参数（xywh和置信度），两个框就是10个参数，后面20个参数是20个类别的条件概率。那么30 = 5 + 5 + 20。

    

    ![image-20231105135559438](/Users/lifangyuan/Desktop/learn/pic/image-20231105135559438.png)

    

    用不同颜色来代表不同的类别，用线条的粗细来代表每个bounding box的置信度，那么形成中间这个结果（98个bounding box，每个bounding box都有置信度，最高类别概率对应的类别），再将中间这张图进行一个后处理（比如说去掉较小置信度的，进行非极大值抑制（NMS）去掉重复的预测框）就获得了最终的目标检测预测结果。

    ![image-20231105141911667](/Users/lifangyuan/Desktop/learn/pic/image-20231105141911667.png)

    

  - **后处理（置信度过滤，NMS）**

    后处理就是把7 * 7 * 30维的张量变成最后的目标检测的结果。

    把98个预测框，进行筛选过滤，把置信度比较低的预测框过滤掉，把重复的预测框只保留一个，最终获得目标检测的结果。

    先拿出一个grid cell来看，一个grid cell包括30个数字（5 + 5 + 20），是两个bounding box + 20个类别的条件概率，那么计算一个bounding box各个类别的全概率就是该bounding box的置信度乘以各个类别的条件概率，那么我们可以得到98个20维的全概率。

    ![image-20231105145540473](/Users/lifangyuan/Desktop/learn/pic/image-20231105145540473.png)

    

     可视化出来，我们获得到了中间的这个乱图

    ![image-20231105152047150](/Users/lifangyuan/Desktop/learn/pic/image-20231105152047150.png)

    98 * 20（98个bounding box 20个类别 的全概率），我们先按行来看，一行代表一个类别，那这个类别中肯定有一些是概率很低的，我们设置一个阈值，把所有小于该阈值的概率一律抹零。再按照概率高低从大到小排序。再对这个排序后的结果进行非极大值抑制（先把最高的拿出来，再遍历小于这个值的每个值，如果他俩的交并比IOU如果他俩的IOU大于某个阈值，那我们就认为他俩重复识别了一个物体，那我们就把低概率的这个过滤掉，（抹零）否则保留；再遍历剩下的值），

    进行20次的NMS，最后98 * 20是一个稀疏矩阵，如果不为0，类别 概率 找出来，可视化出来作为目标检测的结果。 

  - 22

    

- **训练阶段**

  - 监督学习是通过梯度下降和反向传播方法迭代微调神经元的权重，使得损失函数最小化。

    在训练的时候，已经在训练集的每张图片上标注过了ground truth（人工标记bounding box，绿框，标准答案），而算法是为了让预测结果尽量拟合这个绿框，使得损失函数最小化。而绿框落在哪个grid cell里面，就应该由哪个grid cell 产生的bounding box来负责拟合这个绿框（一个grid cell产生2个bounding box 由两者之一拟合绿框，选择和ground truth 交并比大的那个框来拟合，尽可能和ground truth 一样重合，另外一个框什么都不用做），并且grid cell输出的类别也应该是ground truth的类别；其他没有ground truth 落在的grid cell呢？那他预测出的两个框都不用管了，让他们的置信度越小越好，最好为0；这样构建了yolov1的损失函数

    ![image-20231105155121158](/Users/lifangyuan/Desktop/learn/pic/image-20231105155121158.png)

  - 2

- 2

