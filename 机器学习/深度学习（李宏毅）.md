# 深度学习（李宏毅）

## P1：机器学习概述

- 机器学习做的事情是**找一个复杂函数f（x）**

  语音辨识：f（声音讯号） = 声音讯号说的内容

  影像辨识：f（照片） =  照片内容是什么

  GO：f（当前棋局） =  下一步该怎么走

  

- 深度学习是机器学习的一种

- 深度学习做的事情是**找一个复杂函数f（x），而这个复杂函数是类神经网络的一种**

  ​	类神经网络的输入：向量vector、矩阵matrix（图片）、序列sequence（语音、一段文字）

  ​	类神经网络的输出：一个数值scalar（回归regression）、一个类别（机器在你提供的几个选项中选择一个，classification）、生成一段话或者图片等。

  

  ​	作业1（hw1:COVID-19 Case Prediction 确诊率预测）vector -> regression

  ​	作业2（hw2:Phonene Classification 语音辨识简化版）vector -> classification

  ​	作业3（hw3:Image Classification 图片分类）matric -> classification

  ​	作业4（hw4:Speaker Classification 辨别说话的人）sequence -> classification

  ​	作业5（hw5:Machine Translation 机器翻译 句子->句子）sequence -> text

  ​	作业6（Anime Face Generation 动漫人脸的生成）image

  ​	

- 机器怎么找到f（x）呢？

  - 监督学习 supervised learning

    过程：收集训练数据training data，标记训练数据labels，此时喂到网络中，网络学习形成函数f（x）

    缺点：每次任务收集标记数据太费时

  - 自监督学习 self-supervised learning

    我们的期待：我们期待模型训练之前练成各种影像辨识的基本功（pre-train），这个过程不需要任何的标注。只需要网络上一大堆影像的资料，机器就会自动学会基本功。比如说：图像经过翻转颜色变换后问机器它们相同吗。练好基本功之后，下游任务downstream task（真正关心的任务）就会变得容易。

    类比：pre-train vs 下游任务 == 操作系统 vs 应用  

    举例：pre-train model 又称为 foundation model，foundation 中最知名的模型是BERT模型（有340M参数），ELMo、GPT-2、GPT-3、T5

  - 生成对抗网络 generative adversarial network

    解决的问题：在superviased learning中，我们要求有成对的一一对应资料：data1和label1、data2和label2、data3和label3... 但在generative adversatial network中我们不需要data和label成对的一一对应的出现了，只需要有大量的data和大量的label，机器自动就可以把它们之间的关系找出来。

    举例：语音辨识：机器听大量的声音讯号、读大量的文字，机器自动学会做语音辨识

  - 强化学习reinforcement learning （RL）

    什么时候使用：你不知道要怎么标注资料，如下围棋（人类也不知道最好的一个棋应该放在哪里，但是可以判断放在某个位置的好坏）

  - 

  

- 进阶课题（机器学习不止是追求正确率）

  - 异常检测anomaly detection

    什么是异常检测：假设你的分类器可以分辨保卡龙和数码宝贝，但是当它拿到这两种以外的其他物品（真正的暴龙），那么分类器就会说：我不知道。异常检测就是使得分类器可以说我不知道的能力。

  - 可解释性AI explainable AI

    什么是可解释的AI：假设你的分类器可以分辨保卡龙，但是它真的知道保卡龙长什么样子吗，它可以解释这张图片为什么是保卡龙吗，可解释的AI解决的问题是，让机器可以说这是类别A，because...（机器把它觉得重要的部分高亮显示）

  - 模型攻击 model attack

    什么是模型攻击：给定模型一张图片，模型可以判别它的分类，但当我们往图片里面加入一个很小的噪点（改变某一个像素，这叫做模型攻击），模型对它的判别率就会发生变化。

  - 领域适应 domain adaptation

    什么是领域适应：一般我们在做机器学习的时候，往往假设训练数据和测试数据是非常相似的，比如训练数据是只有黑白两色的手写数字，测试数据也是只有黑白两色的数据。领域适应就是训练数据和测试数据不一定非常的相似，比如训练数据是只有黑白两色的手写数字，测试数据除了只有黑白两色的数据还有包括彩色内容的数据。

    ![image-20231214142323932](/Users/lifangyuan/Desktop/learn/pic/image-20231214142323932.png)

  - 模型压缩 network compression

    什么是模型压缩：当电脑的运算资源有限时，很难跑模型，那么就可以把模型压缩，让他们可以跑在手机、手表中。

  - life-long learning

    什么是life-long learning：一个机器每天学一点，那么经过上千年上万年，它就变成一个全能机器人。

  - 元学习（学习如何学习） meta learning = （learn to learn）

    元学习是怎么运作的：开始：人设计学习算法，让机器具备分类的能力。现在：机器从大量的任务中，自己发明新的算法，也就是机器不再使用人设计的学习算法，而是从过去的学习经验里面，发明出新的算法，它希望他可以变得更厉害。

  - 少样本学习 few-shot learning

    少样本学习一般会用到meta learning

  - 

- 

  

## P2 P3：机器学习基本概念 machine/deep learning

- 机器学习：让机器具备找“函数f（x）”的能力，这个函数往往非常复杂。

- 根据找的函数f（x）不同，机器学习有了不同的类别，即有了不同的任务。

  - 回归regression：输出的是一个数值（如，输入今天PM2.5数值、今天的温度，输出明天PM2.5的数值）
  - 分类classification：人们给定很多类别classes，机器根据给定的类别选择其中一个当作输出。（如，准备好选项（yes、no），输入一个邮件，输出是否为垃圾邮件（yes、no））（如alghago也是分类问题，输入为当前棋局，输出为在19*19个选择中选一个位置作为下次着棋点）
  - 产生有结构的物件structured learning：让机器学会创造，如写一篇文章、画一张图。

- 机器学习找函数f（x）的过程（训练）

  - 我们先写出一个带有未知参数的函数

    我们先猜测一下，函数f（x）的数学式到底长什么样。猜 **f（x） = b + wx1** ，其中b、w是未知的，x1是已知的。函数f（x） = b + wx1 就是一个model（model就是带有未知参数的函数）；x1就是feature；w就是weight；b就是bias。

  - 定义一个损失函数loss（loss评价w和b的好坏，到底怎么评价要通过训练数据的历史） 

    loss也是一个函数，loss的输入是model里面的未知参数（b、w），loss输出的值代表如果我们设定了b、w这两个值，那么这两个值好还是不好。如**loss = 求平均|每个真实y值 - 每个预测的y值|**（其中真实y值叫做label，是给定的；而预测的y值是通过f（x）计算得来的）

    绝对值求平均是MAE；差值的平方求平均是MSE；cross-entropy

    ![caa909ee17cd130d80b04a3b94a631c9](/Users/lifangyuan/Library/Containers/com.tencent.qq/Data/Library/Application Support/QQ/nt_qq_0e5b8ceb779c3dde95737825f2ca5ef6/nt_data/Pic/2023-12/Ori/caa909ee17cd130d80b04a3b94a631c9.png)

  - optimization 解一个最优的w、b

    w *，b * = arg min L，找到最优的w和b使得loss函数取得最小值

    这里使用的唯一的方法是**gradient descent梯度下降**，gradient descent怎么做？假设只有一个未知参数w，画出loss和w的x-y轴关系曲线；找一个初始的随机的点w0，拿到w0点处的切线斜率；如果斜率是负的，w变大，如果斜率是正的，w变小。步长怎么定？斜率大步伐就大一点，斜率小步伐就小一点；步长还有学习率n来决定；不断移动w的位置；停止条件：迭代次数够了、误差够小。

    ![image-20231214160043751](/Users/lifangyuan/Desktop/learn/pic/image-20231214160043751.png)

  - **PS**，gradient descent 算微分不会算？可以用工具**backpropagation**

- 拿这个函数到训练集之外的地方的测试（验证），去更改model

  **首先是更改model**

  观察真实y和预测y的对比曲线后，对model f（x）进行修改，而修改不仅来自于对真实y和预测y的对比曲线的观察，还来自于domain knowledge领域知识。对model进行修改一般会增加x（feature）的维度（增加x维度的同时也会增加x对应的weight w的个数），下面这些修改后的模型有一个共同的名字：linear model（y = b + wx，y与x的对应关系**总体上**是线性的直线，改变w不过是改变斜率，改变b不过的将直线上下移动）

  ![image-20231214162150163](/Users/lifangyuan/Desktop/learn/pic/image-20231214162150163.png)

  

  **linear model就是f（x） = b + wx**，其中f（x）与x是线性相关的，这使得linear model 太过简单了，使得linear model有很多局限（这些局限称为model bias）

  那么我们需要写更加复杂、灵活的函数，如**piecewise linear**，这个model中**f（x） = 一个常量 + 若干个_/‾**。这样就算实际要拟合的曲线是曲线或者非常复杂，也可以利用_/‾来拟合，其中一个常量constant是实际要拟合的曲线和y轴的交点，而 若干个 _/‾是c*sigmoid（b+wx1），各式各样形状的 _/‾只需要调整c、w、b即可获得，（改变w会改变s曲线的斜率，改变b会使得s左右移动，改变c会改变s的高度）。

  ![image-20231214174213345](/Users/lifangyuan/Desktop/learn/pic/image-20231214174213345.png)

  此时，我们的model由linear model 变成了 piecewise linear model

  ![image-20231214174606870](/Users/lifangyuan/Desktop/learn/pic/image-20231214174606870.png)

  如果再加入很多个feature呢，其中i代表每个 _/‾，j代表考虑前一天、前两天、前三天（3个feature）

  w矩阵的列表示feature数量、行表示 _/‾的数量

  ![image-20231214174924498](/Users/lifangyuan/Desktop/learn/pic/image-20231214174924498.png)

  画图+矩阵表示：

  ![image-20231214180358269](/Users/lifangyuan/Desktop/learn/pic/image-20231214180358269.png)

  引入矩阵后，化简公式，其中x是feature，w、b、c、b是未知参数。将w拉直为一条、向下拼上b、c、b，形成一个新的一条向量，这个向量里存的都是未知参数，一条形状的，里面不分w、b、c、b了。

  ![image-20231214181546250](/Users/lifangyuan/Desktop/learn/pic/image-20231214181546250.png)

  loss和optimization基本不变，optimization还像之前一样用牛顿法，步长固定（学习率）

  ![image-20231214183213144](/Users/lifangyuan/Desktop/learn/pic/image-20231214183213144.png)

  但是这样算太缓慢了，我们**改进一下loss和optimization的使用方法**

  假设有N条数据，将N条数据分成一组一组的**batch**（怎么分，随便分就可以），一个batch里面有B条数据。之前我们给 一整个N算一个loss再进行一个梯度下降更新迭代点；现在我们不这么做了，现在我们拿第一个batch里面的B条数据（训练后，拿到各个参数的值）得到一个loss L1，牛顿法，得到下一个迭代点的位置，**这叫做一次update**，再训练下一个batch，拿到各个参数的值，得到loss L2，牛顿法，得到下一个迭代点的位置。。。把所有的batch都看过一次叫做**epoch**，（每个batch）每一次更新参数叫做update，把所有的batch都看过一次叫做epoch。

  ![image-20231214185453736](/Users/lifangyuan/Desktop/learn/pic/image-20231214185453736.png)

  

- 对模型做更多的变形

  除了sigmoid _/‾ 还有relu _/（**两个**relu叠加就是 _/‾），其中relu为 c * max（0，b+wx），

  这里的relu和sigmiod都叫做激活函数activation function。sigmiod有几个和w矩阵还有c的行数一样的（i代表有几个sigmiod）。

  ![image-20231214190726731](/Users/lifangyuan/Desktop/learn/pic/image-20231214190726731.png)

- 运算的重复

  ![image-20231214192658967](/Users/lifangyuan/Desktop/learn/pic/image-20231214192658967.png)

- 以上说的就是神经网络neural network，其中一层sigmoid就是一层hidden layer，很多层hidden layer就很深 就是深度学习deep learning；

  2012年Alexnet（8层hidden layer） 2014年VGG（19层 hidden layer） 2014年googleNet（22层 hidden layer） 2015年residual Net（152层 hidden later）

- 那一层只要有足够多的sigmoid/relu _/‾就可以拟合任意一个函数了，为什么还要那么多层hidden layer 要deep呢？**日后再讲**

- 那既然要很多层hidden layer 构建deep，为什么不是越深越好呢？（物极必反，过拟合overfitting了啊，在训练数据上不错，在测试数据上不好） 

- **一个neuron就是一个sigmiod**

## P7：deep learning

- 怎么连接一个一个的神经元呢？可以用全连接前馈网络fully connect feedforward network

  各个参数（w、b、c、b）给定值的网络成为一个函数；各个参数的值发生了变化，那么就变成了另外一个函数；如果只给出网络的架构（形状），不给出具体的参数的值（w、b、c、b），那么这个架构代表的就是一个函数集 function set，有可能这个function set里面包含的所有function都不能很好的解决这个问题，所以决定一个好的function set是非常重要的，决定function set就是决定有多少层layer，每层layer里面有多少个neuron（这个有时候需要一些尝试和domain knowleage），现在也存在一些算法可以自动调整网络的结构形成function set，但是现在还不成熟。

- 全连接前馈网络fully connect feedforward network

  把neuron分成一层一层的，相邻两层的neuron都两两互相连接，各个层里的neuron数量可能是不一样的。

  

  各个层的作用：

  - input layer：接收x

  - hidden layers：特征提取器（以前手动做feature engineering）
  - output layers：multi-class classifier，要通过一个softmax function做分类

  ![image-20231214205506454](/Users/lifangyuan/Desktop/learn/pic/image-20231214205506454.png)

  

  举例：手写数字识别是将16 * 16图像输入到网络中，最后得到一个分类结果的字符串

  - 首先输入16 * 16 图片，会被拉直成256的vector向量（涂黑的地方是1，没有涂黑的地方就是0）

  - 最后输出层用**softmax**的话，那么就会输出各个类别的possibility（那么共有10个类别）

    ![image-20231214210148360](/Users/lifangyuan/Desktop/learn/pic/image-20231214210148360.png)

  - 怎么算loss呢，输出的y是10 * 1的向量（预测值），而实际的y也可以构建成10 * 1的向量，loss就可以计算了
  - 

  

- 

## P*：Pytorch教程1（概述）

- 工具版本

  - Pytorch 0.4、也可以用1.0、1.2
  - Python
  - 线性代数、分布可能性（高斯分布）

- 非常重要的东西：**了解什么是深度学习框架、学会看文档**

- 深度学习属于哪片领域呢？人工智能就是**利用算法进行推理、预测**，人工智能包括专家系统、机器学习等；机器学习包括决策树、贝叶斯、**表示学习**（特征的提取，用更好的方法来表示数据样本的信息）等；表示学习包括浅层的自动编码器、深层的深度学习，深度学习里面包括CNN、RNN、MLP（多层感知器）。

- 开发学习系统的历史过程

  - 基于规则的系统 rule-based systems

    拿到一个输入，手工的设计程序，得到输出。

    所谓手工的设计程序就是构造一批知识库knowledge，构造一批规则。

    这样的系统非常依赖于如何设计这些程序，规则怎么制定（domain knowledge），这样的系统中的规则会越来越多，人会越来越难维护。

    基于规则的学习算法使用算法分析与设计里面的算法比如说广度搜索，深度搜索，图搜索

  - 经典的机器学习方法classic machine learning

    数据输入进来，我们手工的提取特征，然后输入到神经网络mapping from features中去（建立一个映射函数f（x）），得到输出。

    其中**手工的设计来提取特征**有的比较简单，直接**手动筛选**出需要的特征，比如说如果输入的是关系型数据表，那么我们删减某项不相关的特征就可以了（对于关系型数据表，特征features就是某个字段）；有的比较复杂，比如**输入的照片、语音、波形、一段文字等无结构的数据**，我们可以用统计的手法把某一个图像区域变成**一个固定长度的向量/张量**

    其中的神经网络mapping from features 包括线性模型linear model、多层感知器、神经网络。

  - 

- 表示学习representation learning

  - 表示学习与经典机器学最大的区别是：希望features的提取是自动的，而非是人工的。
  - 早期features的提取是单独的一个步骤（利用一个算法），从非常复杂的非结构数据里面提取一个向量出来，然后再把这些features丢到mapping from features 里面去构造函数f（x）
  - 那么为什么要进行特征的提取呢？（维度诅咒：你输入数据的features数量越多，那么对整个样本的数量需求就越多，所以要进行特征的选择）我们需要把特征的维度减少一点，并且我们还希望把高维数据压缩成低维数据（线性或者非线性的空间映射，线性映射需要矩阵），比如我们想把一个N×1维数据变成一个3×1维数据，只需要找到一个3×N的矩阵，用3×N的矩阵去乘以N×1的向量，这样就得到一个3×1维的向量，并且对于这个变化我们希望能够尽量保持高维数据的一些度量信息。这个过程就是表示学习，也就是说我们要学到从高维空间换到低维空间的一个表示。
  - 表示学习有一个分支是manifold流形，（比如说我们说数据分布是在高维空间里的一个低维流形），（流形就是降维，把高维空间坐标降到低维空间系里面去）
  - 深度学习deep learning，最开始我们要训练专门的特征提取器，现在我们用非常简单的特征（**原始特征**）就可以了，然后把它作为输入（原始特征就是比如说我们有一张图片，那我直接把图片里面的像素值拉成一个向量输入进去；我们有一段语音，那我就把波形这个序列给它拿进去；如果是数据库里面的一条记录，二维关系表格那我就把整个记录就给它拿进来，这个记录可能需要做一些基本的处理，比如归一化），拿进来之后，要设计一组独立的额外的层用来提取特征，然后接入到学习器mapping from features 然后再输出。也就是说，这个深度学习输入就是简单的向量，没有经过特征提取，真正的特征提取是通过网络中的前面几层来做的，后面几层是为了构造f（x）
  - 之前最火的是SVM系列，后面是deep learning

- 非常流行的深度学习工具有：tensorflow，caffe2，pytorch，Mxnet
  tensorflow使用的是static gragh静态图；pytorch使用的是dynamic gragh 动态图（在使用完一张图之后就释放掉了，使得可以不断的构造图，非常灵活）

  pytorch有很多网络模板可以用（已经给到了一些卷积、CNN等基本的构件），有自动的梯度计算。

- 

## P*：Pytorch教程2（线性模型Linear model）

- 步骤：

  1. **准备数据集**（训练集training set（x，y）、验证集/开发集dev set（x，y）、 测试集test set（x））

     用训练集的数据对模型进行训练（构建参数），然后拿验证集的数据对它进行评估，如果效果不好的话，那么重新进行训练；如果效果比较好的话，我们就把训练集和验证集的数据合起来对模型再进行一次训练，对测试集投入使用。

  2. **进行模型的选择、设定**（神经网络、决策树、朴素贝叶斯），deep learning对于模型的选择也就是确定一个函数f（x）。

     如果是deep learning的话，那我们可以选择f（x） = ax、f（x） = ax2 + bx + c、f（x） = a e^bx + c等等，每一个不同的f（x）都是一个模型（参数不同也是不同的模型）。通常在选择模型的时候，我们首先会选择一个线性模型linear model 来试验一下是否有效，如果模型不好，我们再更换模型。

     

     **那么如果选定函数形式之后如何确定参数呢？**（如选定f（x） = wx + b，如何进一步确定w和b的值）

     一般先取随机数，然后评估y_hat和y_real之间的差距（loss，loss越小越好。通常用的是平方平均误差MSE），再梯度下降来找到合适的参数值

  3. **进行训练**（KNN不需要训练，但绝大部分都需要training，然后test应用）

  4. **inferring应用**

- training方法

  - 最简单的training的方法：**人工training**（用人眼来找出最合适的权重组合到底是哪一个，或者穷举（作业1就是穷举），或者梯度下降）

    

  - 

- 小实验1：

  - 题目：

    ![image-20231215225942760](/Users/lifangyuan/Desktop/learn/pic/image-20231215225942760.png)

  - 代码：

    我们首先猜测 y = wx

    ```python
    # 导入包（画图包）
    import numpy as np
    import matplotlib.pyplot as plt 
    
    # 导入训练集，x、y一般是要分开的，顺序一一对应 
    x_data = [1.0,2.0,3.0]
    y_data = [2.0,4.0,6.0]
    
    # 定义模型
    def forward(x):
      return x * w
    
    # 定义损失函数
    def loss(x,y):
      y_pred = forward(x)
      return (y_pred - y) * (y_pred - y)
    
    # 把权重和权重对应的损失值都求出来并保存
    w_list = []
    mse_list = []
    for w in range(0.0,4.1,0.1): # w在0.0-4.1范围内每隔0.1采样一次
      print("w:",w)
      l_sum = 0
      
      for x_val,y_val in zip(x_data,y_data):
        y_pred_val = forward(x_val)
        loss_val = loss(x_val,y_val)
        l_sum += loss_val
      print('MSE:',l_sum / 3)
      w_list.append(w)
      mse_list.append(l_sum / 3)
      
      # 绘制图像（二维折线用plt.plot）
      plt.figure('draw')  # 窗口命个名吧
      plt.plot(w_list,loss_list)
      plt.xlabel('w')
      plt.ylabel('loss')
      #plt.pause(5)  # 只显示5s
      #plt.savefig('xxx.jpg')  # 保存图像吧
      plt.show()
      
      
      #--------------------------plt用法--------------------------
      #二维折线
      plt.plot(list1,list2)
      #二维散点
      plt.scatter(list1,list2)
      #添加说明
      plt.xlabel() plt.ylabel()  #添加坐标轴说明
      plt.title()		 #添加标题
      plt.grid(True)    #显示网格
      
      
      # 三维曲面
      import matplotlib.pyplot as plt
      
      plt.figure()
      ax = plt.axes(projection = '3d')
      x = [xxxx]
      y = [xxxx]
      x,y = np.meshgrid(x,y)
      z = np.array([[xxxx]])
      ax.plot_surface(x,y,z,rstride = 1, cstride = 1, cmap = 'rainbow')
      plt.show()
    
    ```

    PS:我们在以后的训练过程中也会经常画这种plt图的（w，loss），但是一般用**epoch做横坐标**，loss做纵坐标，用这个图来看什么时候达到收敛（想要实时绘图就用**visdom**库）

    （断点问题也需要考虑，一共需要训练7天，训练到第6天断电了怎么办）

  - 作业

    ![image-20231215234503623](/Users/lifangyuan/Desktop/learn/pic/image-20231215234503623.png)

  - 画3d图可以用matlab，也可以用py.meshgrid()

  - 

- 

## P*：Pytorch教程3(梯度下降算法)

- 选择一个使得loss函数取得最小值的参数w可以使用试探穷举法，但是不方便，因此引入了梯度下降法。w1 = w0 - 学习率*loss函数的梯度

- 代码（对上次的函数y = w * b 使用梯度下降法求参数w）

  ```python
  import numpy as np
  import matplotlib.pyplot as plt
  
  xs = [1.0,2.0,3.0]
  yx = [2.0,4.0,6.0]
  
  w = 1.0
  def forward(w,x):
    return w * x
  
  def cost(w,xs,ys):
    cost_sum = 0.0
    for x,y in zip(xs,ys):
      y_pred = forward(w,x)
      cost_sum += (y_pred - y) * (y_pred - y)
    
    return cost_sum / len(xs)
  
  def gradient(w,xs,ys):
    gra_sum = 0.0
    for x,y in zip(xs,ys):
      gra_sum += 2 * (w * x - y) * x
    return gra_sum / len(xs)
  
  epoch_list = []
  w_list = []
  loss_list = []
  for epoch in range(1,100):
    loss = cost(w,xs,ys)
    w = w - 0.01 * gradient(w,xs,ys)
    epoch_list.append(epoch)
    w_list.append(w)
    loss_list.append(loss)
  
  plt.figure()
  plt.plot(epoch_list,loss_list)
  plt.xlabel('epoch')
  plt.ylabel('loss')
  plt.show()
      
  ```

- 绘制epoch-loss图的时候，通常曲线会很曲折（有很多震荡），所以我们会使用**指数加权平均来使得曲线稍微平缓**一些，指数加权平均的公式也很简单，用loss表示加权前，loss'表示加权后，那么公式如下，loss‘(0) = loss(0)；loss’(i) = a*loss(i)+ (1-a) *loss'(i-1)

- 绘制出来的epoch-loss图通常为下降曲线，且应该逐渐趋于一个**稳定值**，如果曲线不收敛于一个稳定值，而是抛物线之类的曲线，那么说明训练失败了。**训练失败可能的原因**是：学习率太大了；

- 通常不同梯度下降，而是使用随机梯度下降（李宏毅讲的epoch和batch之间loss的下降方式,mini-batch）

- 

## P*：Pytorch教程4(反向传播back propagation)

- **back propagation** 可以在图上面进行梯度的传播（注意这里的梯度是对loss函数与参数w的计算），帮助我们建立更具有**弹性的模型结构**（function set），一般参数比较简单的时候可以用解析法（列出求导的式子），但当计算较为复杂时（大多数情况，比如说输入5×1，hidden1是6×1，那么中间的w就是6×5），当面对复杂网络时，我们考虑有没有一种算法，可以将网络看作是一个图，使得图中可以传播梯度，最终利用链式法则把梯度求出来，这个算法就叫做反向传播。

- 如果网络只有一层，那么y = w（m * n）*  x（n * 1） + b（m * 1） ；如果网络有两层，那么y = w *（w * x + b）+ b。通过矩阵求导，然后把他的局部梯度都包含在矩阵乘法的模块里；

- 另外就是不管有多少层都是线性的，因为它无论如何都可以化简为y = w' * x + b' ，解决办法：加入sigmoid、relu

- 反向传播算法是有前向和反向的

  ![image-20231216180835893](/Users/lifangyuan/Desktop/learn/pic/image-20231216180835893.png)

- pytorch里面怎么使用前向传播和反向传播？

  - pytorch里面最基本的数据类型：tensor类（用来存数据，标量，向量，矩阵，高维度数据）
    其中数据成员data保存权重的值 grad保存损失函数对权重的导数。

- 代码

  ```python
  import torch
  
  xs = [1.0,2.0,3.0]
  ys = [2.0,4.0,6.0]
  
  w = torch.Tensor([1.0])
  w.requests_grad = True
  
  def forward(x):
    # 这里的w是一个tensor变量，所以乘法被重载了，而且x类型强制转换为了tensor变量。
    return w * x
  
  def loss(x,y):
    y_pred = forward(x)
    return (y_pred - y) * (y_pred - y)
  
  for epoch in range(100):
    for x,y in zip(xs,ys):
      l = loss(x,y) # 搭建计算图
      l.backward()  # 反向传播，得到梯度，与此同时计算图被释放，准备下一次的图
      w.data = w.data - 0.01 * w.grad.data 
      # 若想知道梯度： print(w.grad.item())
      w.grad.data.zero_()# 权重梯度数据清空，如果不清空，下次计算会叠加这次的值！
      
  '''
  需要注意的点：
  	tensor之间的运算即在建立计算图，在代码中，w、y_pred、loss、w.grad都是tensor变量
  	对他们值之间的运算需要w.grad.data，对他们的值显示需要用w.grad.item(),否则会建立计算图
  '''
  
  ```

  

- 作业：利用pytorch反向传播进行二次函数拟合

  ![image-20231218102458032](/Users/lifangyuan/Desktop/learn/pic/image-20231218102458032.png)

- 

## P*：Pytorch教程5（pytorch实战，linear regression）

- 之前学到了如何搭建简单的线性模型，如何训练，如何更新权重；这一讲主要介绍**pytorch工具**帮我们重现线性模型的过程，比如**如何构建自己的model（构造自己的神经网络），如何构造自己的损失函数，如何来构造自己的随机梯度下降的优化器**。

- 之前的步骤

  - 确定模型（forward）
  - 定义损失函数（优化目标），损失函数最后必须是一个标量
  - 优化（随机梯度下降sgd），求导数，更新权重。

- 现在的步骤

  - 准备数据集（后面着重讲，这里先用之前的例子xs,ys）
  - 设计模型（forward，用来计算y_pred）
  - 构造损失函数和优化器sgd（两个对象）
  - 写训练周期（前馈反馈更新，前馈反馈更新，前馈算pre_y和损失，反馈算梯度，更新算权重）

- 代码（虽然比较复杂，但是拓展性非常好，可以用来拓展成卷积神经网络等）

  其中 y = w * x + b

  ```python
  # 这是加注释版讲解代码
  
  import torch
  # 在pytorch中，如果使用mini-batch来构造数据集时，x、y的值必须是矩阵
  #									第一行，第二行，第三行  # 注意这里有两层[]，是矩阵！！
  xs = torch.Tensor([[1.0],[2.0],[3.0]])
  ys = torch.Tensor([[2.0],[4.0],[6.0]])
  # 其中行数代表的是一个batch里面有多少条数据，而列数代表x的维度；y同理
  
  # 当x、y的形状确定下来之后，就可以确定w、b的形状了。
  # backward的使用要求loss必须是一个标量，如果是向量就没办法使用backward了。
  class LinearModel(torch.nn.Module): # 继承自torch.nn.Module
    #这个类中最少要实现两个函数:init和forward（backward自动实现，但是也可以自己定义，继承自Function类，实现backward）
    
    # 构造函数(初始化)
    def __init__(self):
      super(LinearModel,self).__init__()#调用父类的构造，必须要有的
      self.linear = torch.nn.Linear(1,1)# 参数：输入样本的维度，输出样本的维度，bias要不要偏置量（默认为true）
      
      # torch.nn.linear是一个类，tourch.nn.linear(1,1)是构造一个对象，这个对象包含了权重w和偏置b这两个tensor，所以可以利用linear完成w * x + b 这个操作
      
    # 前馈函数，执行计算
    def forward(self,x):
      y_pred = self.linear(x)  # 对象后面加括号，意味着我们实现了一个callable（可调用的对象），实现了w * x + b
      return y_pred
    
  #使用时，直接 model = LinearModel();model(x)就可以了
  model = LinearMOdel()
  
  criterion = torch.nn.MSELoss(size_average = False)# 有两个参数：size_average求不求均值，reduce是不是要求和降维（一般不用）
  
  optimizer = torch.optim.SGD(model.parameters,lr = 0.01) # model里面的所有权重和bias 参数包括params，学习率（可以不同部分使用不同学习率），后面参数一般不变
  # pytorch里面提供了非常多的优化器，如
  #torch.optim.SGD
  #torch.optim.Adagrad
  #torch.optim.Adam
  #torch.optim.Adamax
  #torch.optim.ASGD
  #torch.optim.LBFGS
  #torch.optim.RMSprop
  #torch.optim.Rprop
  
  for epoch in range(100):
    y_pred = model(xs)
    loss = criterion(y_pred,ys)
    print(epoch,loss)
    optimizer.zero_gard()  #梯度归零
    loss.backward()  # 反向传播
    optimizer.step()  # 更新
    
    #训练的循环： 求y_pred,loss（这两步就是前馈）,权重清0，反向传播，更新权重 
    
    #输出w和b的值
  print(model.linear.weight.item())
  print(model.linear.bias.item())
  
  # 测试
  x = torch.Tensor([4.0])
  y = model(x)
  print(y.item())
  
  ```

  ```python
  # 不加注释版代码
  import torch
  import matplotlib.pyplot as plt
  
  #步骤1:准备数据集
  xs = torch.Tensor([[1.0],[2.0],[3.0]])
  ys = torch.Tensor([[1.0],[2.0],[3.0]])
  
  #步骤2:构建模型model
  class LinearModel(torch.nn.Module):
    def __init__(self):
      super(LinearModel,self).__init()
      self.linear = torch.nn.Linear(1,1)
    def forward(self,x):
      y_pred = self.linear(x)
      return y_pred
    
  model = LinearModel()
  
  #步骤3:构造损失函数和优化器
  criterion = torch.nn.MSELoss(size_average = False)
  oprimizer = torch.optim.SGD(model.parameters(),lr = 0.01)
  
  
  #步骤4:迭代
  epoch_list = []
  loss_list = []
  w_list = []
  b_lit = []
  
  for epoch in range(100):
    # 前向
    y_pred = model(xs)
    loss = criterion(y_pred,ys)
    #后向
    optimizer.zero_grad()
    loss.backward()
    #更新
    optimizer.step()
    
    epoch_list.append(epoch)
    loss_list.append(loss.item())
    w_list.append(model.linear.weight.item())
    b_list.append(model.linear.bias.item())
    
  
  
  #步骤5:测试
  x = torch.Tensor([4.0])
  y = model(x)
  print("result:",y)
    
  #额外步骤：画图(plt，list)
  plt.figure()
  plt.plot(epoch_list,loss_list)
  plt.plot(epoch_list,w_list)
  plt.plot(epoch_list,b_list)
  plt.show()
  ```

- 

## P*：Pytorch教程6（logistic regression做分类问题）

- regression回归处理连续的问题（可以画成函数图的），classification分类处理离散的问题。

- 这一讲主要讲机器学习任务里面的分类问题（主要讲**logistic regression**，叫回归但它是做分类的，一张图片输出10个值，10个概率，选最大的值）

- 数据集：mnist手写数字识别（训练60000，测试10000）最后的结果是[0,1,2,3,4,5,6,7,8,9]中的一个；CIFAR10数据集（训练50000，测试10000，彩色图像10个类别）

- **torchvision是torch的一个工具包**，其中有一个包datasets提供相应的数据集。

  ```python
  import torch
  import torchvision
  
  train_set = torchvision.datasets.MNIST(root='xxx',train = True,download = True)
  test_set = torchvision.datasets.MNIST(root='xxx',train = False,download = True)
  
  train_set = torchvision.datasets.CIFAR10(root = 'xxx',train = True,download = True)
  test_set = torchvision.datasets.CIFAR10(root='xxx',train = False,download = True)
  
  ```

- 分类问题有二分类问题，这个时候只需要输出一个值就可以啦，这个值表示取其中某个分类的可能性，那么取另外一个分类的可能性就是1-该可能性。如果结果非常接近0.5（0.4-0.6），那么就输出“不确定”

- 那么如何利用logistic回归来做分类问题呢？

  输入的内容是线性的，是一个R范围内的实数，那么我们把这个实数映射到**[0,1]**之间这个函数叫做**logistic函数（是最具有典型性的sigmoid函数）**，[0,1]非常方便的进行概率转化！！一般论文中它被写作![image-20231218163232164](/Users/lifangyuan/Desktop/learn/pic/image-20231218163232164.png)

  

  向左右两边无穷走，导数绝对值越来越小的函数叫做饱和函数，一般在0-1之间或者-1-1之间，这样的函数有tanh函数，erf，logistic等函数。

  

- **如何选择激活函数呢？ 如果我们的问题希望输出值为概率（加起来是1）那么用logistic（sigmoid），如果我们希望输出值均值为0，那么用tanh等函数** 

  

- **二分类问题的损失函数（BCE）：**

  ![image-20231218165151494](/Users/lifangyuan/Desktop/learn/pic/image-20231218165151494.png)

- 那么linear model和logistic regression model有什么区别呢？

  - Linear model

    ```python
    class LinearModel(torch.nn.Module):
      def __init__(self):
        super(LinearModel,self).__init__()
        self.Linear = torch.nn.Linear(1,1)
      def forward(self,x):
        y_pred = self.linear(x)
        return y_pred
    ```

  - linear loss

    ```python
    criterion = torch.nn.MSELoss(size_average = False)
    ```

    

  - Logistic regression model

    ```python
    import torch.nn.functional as F
    # torch.nn.functional 里面包含了好多激活函数，比如说sigmoid、relu、tanh等等
    class LogisticRegressionModel(torch.nn.Module):
      def __init__(self):
        super(LogisticRegressionModel,self).__init__()
        self.linear = torch.nn.Linear(1,1)
      def forward(self,x):
        y_pred = F.sigmoid(self.linear(x))
        return y_pred
    ```

  - LogisticRegression loss(BCE cross-entropy交叉熵，只用于二分类)

    ```python
    criterion = torch.nn.BCELoss(size_average = False)
    ```

  - 

- 

## P*：Pytorch教程7(多维特征输入，分类输出，最常见的哦)

- 任务：糖尿病分类（8 feature）

  x 和 y记得分开放到变量x，y里

  ![image-20231218172553052](/Users/lifangyuan/Desktop/learn/pic/image-20231218172553052.png)

- 数据集可以去网上找，也可以去tochvision.datasets里面找，也可以去sklearn里面（有糖尿病）找

- 代码（搭建神经网络也就是一个映射 features，8D->6D->4D->2D->1D）

  ```python
  self.linear1 = torch.nn.Linear(8,6)
  self.linear2 = torch.nn.Linear(6,4)
  self.linear3 = torch.nn.Linear(4,1)
  ```

  ```python
  # 带注释的代码
  '''
  	sigmoid有很多地方有
  	比如说torch.nn.functional.sigmoid() 放到forward里面去
  	比如说torch.nn.Sigmoid  放到init里面去
  	relu属于[0,1]
  '''
  
  # 读取数据
  import numpy as np
  xy = np.loadtxt('xxx',delimiter = ',',dtype = np.float32)# 一般读取数据类型为np.float32,因为网络用cpu、gpu通常处理的数据类型都是float32
  
  # numpy数据类型向torch的转变
  xs = torch.from_numpy(xy[:,:-1])
  ys = torch.frmo_numpt(xy[:,[-1]]) #保证输入的值均为矩阵，所以是xy[:,[-1]],而不是xy[:,-1]
  
  #构建模型
  import torch
  class Model(torch.nn.module):
    def __init__(self):
      super(Model,self).__init__():
      self.linear1 = torch.nn.Linear(8,6)
      self.linear2 = torch.nn.Linear(6,4)
      self.linear3 = torch.nn.Linear(4,1)
      self.sigmoid = torch.nn.Sigmoid()
    def forward(self,x):
      x = self.sigmoid(self.linear1(x))
      x = self.sigmoid(self.linear2(x))
      x = self.sigmoid(self.linear3(x))
      return x
    
  model = Model()
  criterion = torch.nn.BSELoss(size_average = False)
  optimizer = torch.optim.SGD(model.parameters(),lr = 0.01)
  
  for epoch in range(100): #这里用的并不是minibatch，而是全部数据丢进去了，如何使用batch要用dataloader，后面再讲
    y_pred = model(xs)
    loss = criterion(y_pred,ys)
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()
  ```

- 

## P*：Pytorch教程8（加载数据集）

- **dataset**用于构造数据集，构造之后数据集得支持通过索引下标拿出某一条数据

- **dataloader**用于拿出一个mini-batch

  为什么要用mini-batch？

  - 如果update一次，使用全部数据集

    优：可以最大化利用向量计算的优势，来提升计算的速度

    缺：性能并不好

  - 如果update一次，使用一条数据

    优：得到比较好的随机性，可以帮我们跨越优化当中遇到的鞍点，性能可能会更好

    缺：计算速度慢

  - 综合一下，使用mini-batch 来均衡一下

- 概念理解

  - epoch，训练周期

    一个epoch有若干个iteration

  - batch_size 批量大小

    一小部分样本的容量

  - iteration

    所有样本都完成一次前向、反向，一共完成了多少次mini-batch。

- 引入mini-batch之后的迭代

  ```python
  for epoch in range(traning_epochs):
   #每次epoch
    for i in range(total_batch)
    #执行一次mini-batch
  ```

  

- **dataloader 数据加载器**

  - 参数：batch_size和shuffle。batch_size的指定，shuffle把数据集打乱顺序
  - 前提：需要知道每条数据的索引，需要知道数据集的长度，知道这两者就可以自动进行小批量数据的生成
  - 步骤：先打乱数据样本，再分组成batch

- 注释讲解代码

  ```python
  import torch
  from torch.util.data import Dataset  #dataset是抽象类，不能实例话，只能被其他子类继承，要想定义dataset，必须继承它，构造自己的dataset
  from torch.util.data import Dataloader  #加载数据，划分batch，可以实例化
  
  class DiabetesDataset(Dataset):
    def __init__(self):
      pass
    def __getitem__(self,index):  # 支持索引
      pass
    def __len__(self):  # 知道数据集中数据条数
      pass
  
  
  dataset = DiabetesDateset()  #定义好dataset类之类，我们才可以实例化 
  train_loader = DataLoader(dataset = dataset,batch_size = 32,shuffle = True,num_workers = 2)# num_workers 是在构成mini-batch时，读数据时，用几个进程来读
  
  #想要定义dataset类，实现索引和获得长度，我们有两种方法
  '''方法一
  	在init函数中，把所有数据都读到变量里（矩阵、张量）
  	每次使用getitem时，直接传出就可以了
  	
  	适用于：数据集不大，比如说结构化的数据表（数据库表格）
  	不适用于：图像数据
  '''
  
  '''方法二（更一般的情况）
  	init函数不读文件，只是做初始化，如：存数据集x的文件名到变量中，存数据集y的文件名到变量中（）如果y的数据量不大，那就直接把y存到变量中就可以了
  	在getitem里面，我们通过读取变量中的文件名，进而读取数据文件
  	
  	适用于：数据集比较大，比如说图片，音频
  '''
  
  #迭代(记得放到main函数里) 
  if __name__ == '__main__':
    for epoch in range(100):
      for i,data in enumerate(train_loader,0):
  ```

  

- dataset类的构造

  ```python
  #方法一
  class DiabetesDataset(Dataset):
    def __init__(self,filepath):
      xy = np.loadtxt(filepath,delimiter = ',',dtype = np.float32)
      self.x_data = torch.from_numpy(xy[:,:-1])
      self.y_data = torch.from_numpy(xy[:,[-1]])
      self.len = xy.shape(0)
    def __getitem__(self,index):  # 支持索引
      return self.x_data[index],self.y_data[index]
    def __len__(self):  # 知道数据集中数据条数
      return self.len
    
  dataset = DiabetesDataset('xxx')
  train_loader = Dataloader(dataset,batch_size = 32,shuffle = True,num_workders = 2)
  
  for epoch in range(100):
    for i ,data in enumerate(train_loader,0):#从data_loader里面可以获得x和y（是矩阵了，而且是tensor）
      # 准备数据(多了这里！！！)
      inputs,labels = data
      #前馈
      y_pred = model(inputs)
      loss = criterion(y_pred,labels)
      
      #反馈
      optimizer.zero_grad()
      loss.backward()
      
      #更新
      optimizer.step()
  ```

  

- 总的代码

  ```python
  import torch
  from torch.utils.data import Dataset,DataLoader
  import numpy as np
  import matplotlib.pyplot as plt
  
  
  # 构造数据集
  class DiabeteDataset(Dataset):
      def __init__(self,filepath):
          xy = np.loadtxt(filepath,delimiter=',',dtype=np.float32)
          self.x = torch.from_numpy(xy[:,:-1])
          self.y = torch.from_numpy(xy[:,[-1]])
          self.len = xy.shape[0]
  
      def __getitem__(self, index):
          return self.x[index],self.y[index]
  
      def __len__(self):
          return self.len
  
  dataset = DiabeteDataset('xxx')
  dataLoader = DataLoader(dataset,batch_size=32,shuffle=True,num_workers=2)
  
  #构造模型
  class Model(torch.nn.Module):
      def __init__(self):
          super(model,self).__init__()
          self.linear1 = torch.nn.Linear(8,6)
          self.linear2 = torch.nn.Linear(6,4)
          self.linear3 = torch.nn.Linear(4,1)
          self.active = torch.nn.Sigmoid()
  
      def forward(self,x):
          x = self.active(self.linear1(x))
          x = self.active(self.linear2(x))
          x = self.active(self.linear3(x))
          return x
  
  # 构造损失函数和优化器
  model = Model()
  criterion = torch.nn.BCELoss(size_average=False)
  optimizer = torch.optim.SGD(model.parameters(),lr = 0.01)
  
  
  epoch_list = []
  loss_list = []
  for epoch in range(100):
      loss = 0.0
      for i,data in enumerate(dataLoader):
          x,y = data
          y_pred = model(x)
          loss = criterion(y_pred,y)
          optimizer.zero_grad()
          loss.backward()
          optimizer.step()
  
      epoch_list.append(epoch)
      loss_list.append(loss.item())
  
  plt.figure()
  plt.plot(epoch_list,loss_list)
  plt.show()
  ```

  

- **数据集**

  torchvision.datasets 里面提供了很多数据集，且他们都实现了getitem() 和 len()，**所以它们可以用dataloader来加载**，并且可以使用多进程加速。

  

  **如**mnist、fashion-mnist、emnist、coco、lsun、imagefolder、datasetfolder、imagenet-12、cifar、stl10、phototour

  

  加载:

  ```python
  train_data = torchvision.datasets.xxxx(root = 'xxx',train = True,download = True,transform = transform.ToTensor())
  
  test_data = torchvision.datasets.xxxx(root = 'xxx',train = False,download = True,transform = transform.ToTensor())
  
  train_loader = Dataloader(train_data,batch_size=32,shuffle = True,num_workers=2)
  test_loader = Dataloader(test_data,batch_size=32,shuffle = False,num_workers=2)
  # 通常test不做shuffle，还有就是两者的batch_size一样的
  ```

  

- 作业根据其他特征来判断是否存活

  ![image-20231218215542601](/Users/lifangyuan/Desktop/learn/pic/image-20231218215542601.png)

- Ps1：**记得把迭代epoch放到main函数里面去，这是pytorch的bug！**

- Ps2：在构造损失函数时，用reduction = 'mean'来代替size_average = True ,这是新版本的要求

## P*：Pytorch教程9(多分类问题)（用softmax分类器）

- 本节问题：

  - 如何用softmax分类器解决多分类问题
  - 如何利用pytorch实现多分类

- 如果我有10个分类那么我的神经网络怎么设计呢？

  - 方法一

    我们把每一个类别看作**是二分类**的问题（每个类别都是一个二分类问题，每个类别输出一个值，这个值在0-1之间），在神经linear层最后输出的时候，直接输出10个数字，每个输出作为该分类的概率；损失函数也很好算（**真实值为[0,0,0,1,0,0,0,0,0,0],预测值为[0.8, 0.3, 0.9, 0.1, 0.4, 0.6, 0.3, 0.7, 0.1, 0.1]**，计算每个类别的loss并相加即可）

  - 方法二（更一般的情况，**采用**）

    因为每个输入最终只属于一个分类，那么按理说，各个输出直接应该有相互抑制的作用（属于一个分类之后，就不可能再属于另外的分类了；一个分类值大，那么另外所有的分类值就应该小），所以我们不采用上面的方法，反而我们期待的是：**各个分类的输出值都属于[0,1]之间，所有分类的输出值之和为1**。

    所以在神经网络中，我们用sigmoid来处理前面的层，只有最后一层我们使用softmax（它可以输出一个分布，使得每一个分类都在[0,1]之间，且各个分类的输出值加起来=1）。

    softmax函数如图所示：

    ![image-20231219120741519](/Users/lifangyuan/Desktop/learn/pic/image-20231219120741519.png)

    那么使用softmax之后，我们的损失函数如何定义，

    ![image-20231219121247296](/Users/lifangyuan/Desktop/learn/pic/image-20231219121247296.png)

- 多分类问题的loss计算实现（当然是方法二啦）

  - numpy实现

    ```python
    # 假设softmax激活函数之前的网络输出的是z向量
    y_pred = np.exp(z) / np.exp(z).sum()  # 利用softmax求概率分布
    loss = (-y * np.log(y_pred)).sum()  # 求y与y_pred之间的损失
    ```

  - torch实现（**采用**）

    ```python
    # 更为普遍的是将softmax和loss损失和在一起（求e的x次方得到分布，再用sum(-y * log(y_pred))求损失，这两个步骤合并为交叉熵损失cross entropy loss）
    # 注意！！这里假设softmax激活函数之前的网络输出的是z向量,这里的z仍是tentor类型，最后一层不做激活啦！！！！直接交给cross entropy loss
    # 但！！！需要注意的是要使用cross entropy loss 要求y必须是longTensor类型的
    y = torch.longTensor([0])
    z = torch.Tensor([0.2,0.1,-0.1])
    criterion = torch.nn.CrossEntropyLoss()
    loss = criterion(z,y)
    print(loss)
    
    # cross entropy loss vs NLLLoss
    # cross entropy loss == logSoftMax + NLLLoss
    ```

    

- 手写数字分类MNIST

  - 导入模块

    ```python
    import torch
    from torch.utils.data import Dataset,Dataloader
    import torch.nn.functional as F # 激活函数
    from torchvision import datasets
    from torchvision import transforms  # 针对图像进行原始处理
    import torch.optim as optim  # 优化器
    ```

  - 准备数据集（图像数据处理，先toTensor，再normalize）

    ```python
    # 图像读进来一般是W*H*C，（C就是channel，通道，一般是3/1），但是输入到神经网络里面，一般要变换成C*W*H，这是为了更高效的卷积处理；还有就是把每个像素值都变成[0,1]之间的数，这也是为了高效处理数据;   所以会将读入的28*28的PIL image类型进行处理得到1*28*28的tensor类型，且将每个像素值由[0,255]变到[0,1].   这个过程由transform里面的toTensor来实现,除了变tensor记得还要归一化，归一化用transforms.normalize((均值,),(标准差,))。
    trans_form = transforms.Compose([transform.toTensor(),transform.normalize((0.1307,)(0.3081,))])
    
    train_dataset = datasets.MNIST(root = 'xxx',train = True,download = True,transform = trans_form)
    train_loader = DataLoader(train_dataset,batch_size = 64,shffule = True,num_workers = 1)
    
    test_dataset = datasets.MNIST(root = 'xxx',train = False,download = False,transform = trans_form)
    test_loader = Dataloader(test_dataset,batch_size = 64,shuffle = False,num_workers = 1)
    ```

  - 搭建网络

    ```python
    # 因为分了mini-batch，所以输入的数据是batch_size * 1 * 28 * 28
    # 不合适，我们要把1 * 28 * 28拉直，把输入的数据变成batch_size * 784, 使用view来实现！！！ 如x.view(-1,784)(转变为二维向量，784表示784列，-1表示这个值自动去算)，算到这里我们拿到的输入是N*784的矩阵（N个样本，每个样本的特征是784个）要求输出（N*10）
    
    class Model(torch.nn.Module):
      def __init__(self):
        super(model,self).__init__()
        self.linear1 = torch.nn.Linear(784,512)
        self.linear2 = torch.nn.Linear(512,256)
        self.linear3 = torch.nn.Linear(256,128)
        self.linear4 = torch.nn.Linear(128,64)
        self.linear5 = torch.nn.Linear(64,10)
      def forward(self,x):
        x = x.view(-1,784)  # 拉直，变成N*784
        x = F.relu(self.linear1(x))
        x = F.relu(self.linear2(x))
        x = F.relu(self.linear3(x))
        x = F.relu(self.linear4(x))
        x = self.linear5(x) # 最后一层不做激活输入到cross entropy loss 里面去
        return x
     
    model = Model()
    
    ```

  - 构建损失和优化器

    ```python
    criterion = torch.nn.CrossEntropyLoss()
    optimizer = torch.optim.SGD(model.parameters(),lr = 0.01,momentum = 0.5) # 动量，来优化梯度下降
    ```

  - 迭代之训练

    ```python
    def train(epoch):
      loss_sum = 0.0
      
      for batch_idx,data in enumerate(train_loader):
        x,y = data
        optimizer.zero_grad()
        y_pred = model(x)
        loss = criterion(y_pred,y)
        loss.backward()
        oprimizer.step()
        loss_sum += loss.item()
        
        if batch_idx % 300 == 299:
          print("(%d,%d) loss:%.3f" %(epoch+1,batch_idx+1,loss_sum/300))
          loss_sum = 0.0 
    ```

  - 迭代之测试

    ```python
    def test():
      correct = 0
      total = 0
      
      with torch.no_grad():
        for data in test_loader:
          x,y = data
          output = model(x)
          _,y_pred = torch.max(output,dim=1)# N*10的数据，从维度1入手，挑出最大值，返回值和下标
          total += len(y)
          correct += (y_pred == y).sum().item()
      print('acc:'correct/total)
    ```

  - 训练迭代

    ```python
    if __name__ == '__main__':
      for epoch in range(10):
        train(epoch)
        test()
        
    ```

    

- 作业

  ![image-20231219141649486](/Users/lifangyuan/Desktop/learn/pic/image-20231219141649486.png)

## **P*：Pytorch教程小结**

- 步骤：

  1. 数据准备

     - 自己构造数据集/从模块里拿到数据集dataset
     - 实现dataloader

  2. 构造模型

     - init
     - forward

  3. 构造损失函数、优化器

     - criterion 损失函数的选择
     - optimizer 优化器的选择，一般是SGD

  4. 迭代之训练

     - 在train_loader里面一次一次的训练batch

     - 前向  y_pred、loss的计算
     - 后向 optimizer清空、loss的backward
     - 更新 optimizer.step
     - 叠加每个小batch的loss，算一个sum_loss，等batch_idx % 300 == 299 时，可以进行一次输出 epoch, batch_idx,loss_sum

  5. 迭代之测试

     - 在test_loader里面一次一次取出batch
     - 计算y_pred
     - 叠加total和correct，计算acc

  6. main函数执行

     - for epoch in range(xx):

       ​	train(epoch)

       ​	test()

     - 一定要main函数内执行，不然会报错

- 数据集
  - 可以去**torch vision.datasets**里面获取，通过torch vision.datasets.xxx(root = 'xxx',train = True/False,download = True/False,transform = xxx(自定义/调用已有方法))
  - 如果是从torchvision.datasets里面获取的数据集，那就不用再自己构造数据集了，直接**构造dataloader**，dataloader = torch.utils.data.Dataloader(dataset,batch_size = batch_size,shuffle = True/False,num_workers = 1/2/3/4..)，这样就产生了mini-batch
  - 如果数据集是自己构造的，那么需要**构建自己的dataset类**，继承自torch.utils.data.Datasets,需要在里面实现__ init __ 、 __ get item __ 、__ len __ 方法（为了dataloader可以正常运行），实现方法有两种：1.如果数据集的数据量比较小，那么就直接在init的时候把所有数据都存入变量xs、ys中，在 __  get item __ 方法中，直接通过下标返回相应的值；2.如果数据集的数据量比较大，那么在init的时候把所有数据的文件名都存入变量xs、ys中，在 __  get item __ 方法中再取出对应的数据，并返回。需要注意的是不管是哪种方法，**我们的xs、ys（输入、输出）都要分开存储**
- 对于线性的回归问题
  - 我们一般采用简单的linear，除了最后一层，前面每层后面都加一个激活函数（任君挑选）
  - 损失函数使用MSE
- 对于二分类问题
  - 我们一般采用简单的linear，每层后面加一个sigmoid，这个激活函数也可以换成是其他函数，但是要求这个激活函数y的取值范围是[0,1]，因为我们要输出的是一个概率分布！（tanh和relu就不行，因为他们的取值范围是[-1,1]）
  - 损失函数使用BCE，BCE就是（-y * log(y_pred)）
- 对于多分类问题
  - 多分类问题一般采用简单的linear，除了最后一层，前面每一层后面都要加一个激活函数（任君挑选）
  - 多分类问题的损失函数一般有两种选择：1.crossEntropyLoss，这个损失函数要求神经网络的最后一层不需要激活函数，且最后一层的类型是Tensor类型，而y类型是longTensor类型。2.softmax + NLLLoss，这个基本等价于crossEntropyLoss，不过这种方法要求神经网络最后一层用softmax激活（变成一个分布概率），然后再丢到NLLLoss里面去
  - 输出N * M，N是变量个数，M是属于各个分类的可能性，选最大的就可以了，这里用value,index = torch.max(output,dim = 1)，其中value表示最大可能性的值，index表示最大可能性所在的下标
- 对于图片
  - 一般图片输入进来都是W * H * C，应该先把将它变换成**C * W * H** ，再将转换成**tensor类型**的变量（这两步工作torchvision.transforms.toTensor()做了）；
  - 然后对图片进行**归一化**（像素值从[0,255]->[0,1]），这步工作交给torchvision.transforms.Normalize((均值, ), (标准差, )),这里需要知道数据集**整体**的均值和标准差
  - 上面这两个步骤一般在数据准备的时候就已经做了，然而我们输入到神经网络中时，一般要数据是二维的，也就是说要把每行图片的数据**“拉直”**，形成N * 784的矩阵（其中N代表数据样本数量，784是每张图片的像素总值，也叫基础特征，初始特征是全部像素784），这一步可以在model的forward函数里面用x = x.view(-1,784)来实现（变成2维矩阵 N * 784，其中-1表示一维大小自动计算）
  - 另外就是图片数据比较大的时候，优化器记得加参数momentum = 0.5(加入动量，算的快)
  - 
- 

## P*：Pytorch教程10（基础CNN）

- 网络中如果用的都是linear并且串联起来叫做线性层，相邻两层之间各个节点都互相连接（没有不连接的），这是全连接神经网络fully connected

- **构建卷积神经网络首先我们要明白输入数据的维度是什么，输出数据的维度是什么。**

- **卷积层convolution和下采样层subsampling（两者合起来称为特征提取器）**

  **图像通过卷积层是做什么的？保留图像的空间特征**（全连接网络中输入图像，本来上下两个像素点非常有关联，但被“拉直”之后，两个像素点离得却非常远，这没有保留图像的空间特征），卷积神经网络是把图像**直接按照原始的空间结构来进行保存**，这样的话，我们就能保持原始的空间信息。

  

  经过一个卷积层convolution（如4 * 24 * 24）之后，我们得到的图像通道宽度高度都可能发生变化（C * W * H变了，但是张量仍然是三维的），然后再去下采样subsampling，通道不变，宽度高度变化，下采样的目的是减少数据量，降低运算量 

- 卷积神经网络的过程：convolution、subsampling、convolution、subsampling、｜（至此为特征的提取）｜展开成一维张量、fully-connected、softmax｜（这里是特征的分类）｜

  ![image-20231219163245657](/Users/lifangyuan/Desktop/learn/pic/image-20231219163245657.png)

- 图像一般是RGB三个通道的，3 * W * H；**从三层里面“切”一块出来叫做patch**（3 * W' * H' ，patch的选取是在图片上进行慢慢滑动，“遍历一次”，切出来都是厚厚的一块），然后对图像做卷积（针对patch来做的），它的通道宽度高度都有可能发生变化，变为C'' * W'' * H''，新的patch通道数量叫做输出通道数（厚度），输出通道里的每一个值都是之前patch里面的每一个像素值与权重相乘的和，所以它的值包括了之前patch里面的某种信息，不断的卷积就会检测某种特征。满足特征的话值比较大，不满足的话值比较小

  ![image-20231219164637215](/Users/lifangyuan/Desktop/learn/pic/image-20231219164637215.png)

- 卷积计算过程

  - 单通道卷积 （只有一个卷积核， 输入数据与它数乘求和）

  ![image-20231219165819748](/Users/lifangyuan/Desktop/learn/pic/image-20231219165819748.png)

  - **多通道卷积**（**卷积核的通道数= 图像的通道数**，每个通道卷积之后，记得做**求和**）（**一个卷积核像订书钉一样，原图像像纸一样，订一下，厚度消失且变成一个小格**了（究极sum叠加），C  * 3 * 3的卷积核会使得图像的长宽-2），**遍历原图像一次，就可以得到“一张”中间结果，那么多来几个卷积核，就可以得到厚厚的中间结果（拼接）**也就是说，有几个卷积核中间结果就有几个channal

    计算过程：

    ![image-20231219171849688](/Users/lifangyuan/Desktop/learn/pic/image-20231219171849688.png)

    

    叠加：

    ![image-20231219172234633](/Users/lifangyuan/Desktop/learn/pic/image-20231219172234633.png)

    m和n对应关系：

    ![image-20231219173840383](/Users/lifangyuan/Desktop/learn/pic/image-20231219173840383.png)

    所以卷积核的维度应该是：

    ![image-20231219174317627](/Users/lifangyuan/Desktop/learn/pic/image-20231219174317627.png)

    

- 代码讲解（conv怎么用）

  ```python
  conv_layer = torch.nn.Conv2d(in_channal,out_channels,kernel_size，stride = 2,padding，bias = False)
  #输入通道数、输出通道数、卷积核大小（可以是3，默认3*3；也可以是（5，3）就是5*3）、步长、填充几圈，偏置
  ```

  卷积核的输入通道必须和原图像的输入通道一致；卷积核的输出通道必须和输出图像的通道数一致。

  ![image-20231219175033577](/Users/lifangyuan/Desktop/learn/pic/image-20231219175033577.png)

- padding变量指的是填充一圈0

  如果卷积核是3 * 3，想要使得输出图像的W和H不变，那么就填充一圈padding = 1；（1 = 3 // 2）

  如果卷积核是5 * 5，想要使得输出图像的W和H不变，那么就填充两圈padding = 2；（2 = 5 // 2）

- 代码讲解

  ```python
  import torch
  
  input = [3,4,5,6,7,
           2,4,6,8,2,
           1,6,7,8,4,
           9,7,4,6,2,
           3,7,5,4,1,]
  input = torch.Tentor(input).view(1,1,5,5)
  # batch,channel,width,height
  
  conv_larer = torch.nn.Conv2d(1,1,kernal_size = 3,padding = 1,bias = False)
  
  kernal = torch.Tensor([1,2,3,4,5,6,7,8,9]).view(1,1,3,3)
  conv_layer.weight.data = kernal.data
  
  output = conv_layer(input)
  ```

  

- 下采样（用得最多的是maxpooling）通道数量不变，图像大小变小，不设定stride，那么stride默认和kernal——size一样大，其实图像大小也可以不变，这个时候要设定padding（3*3 pooling 要设定pooling = 1；5 * 5 pooling要设定padding = 2）

- 代码（maxpooling）

  ```python
  import torch
  
  input = [3,4,6,5,
          2,4,6,8,
          1,6,7,8,
          9,7,4,6]
  input = torch.Tensor(input).view(1,1,4,4)
  
  maxpooling_layer = torch.nn.MaxPool2d(kernal_size = 2)
  output = maxpooling_layer(input)
  ```

  

- minist手写数字集手算维度

  ![image-20231219181447003](/Users/lifangyuan/Desktop/learn/pic/image-20231219181447003.png)

- 模型定义代码

  ```python
  class Model(torch.nn.Module):
    def __init__(self):
      super(Model,self).__init()
      self.conv1 = torch.nn.Conv2d(1,10,kernal_size = 5)
      self.conv2 = torch.nn.conv2d(10,20,kernal_size = 5)
      self.pooling = torch.nn.MaxPool2d(2)
      self.linear = torch.nn.Linear(320,10)
      
    def forward(self,x):
      batch_size = x.size(0)
      x = F.relu(self.pooling(self.conv1(x)))
      x = F.relu(self.pooling(self.conv2(x)))
      x = x.view(batch_size,-1)
      x = self.linear(x)
      return x
  model = Model()
  
  '''
  				b 1 28 28
  conv1(1,10,5,5)
  				b 10 24 24
  maxpool(2)
  				b 10 12 12
  relu()
  				b 10 12 12
  conv2(10,20,5,5)
  				b 20 8 8
  maxpool(2)
  				b 20 4 4
  relu()
  				b 20 4 4
  				b 320
  linear(320,10)
  				b 10
  
  '''
  ```

  

- 怎么使用gpu呢

  ```python
  device = torch.device('cpu')
  device = torch.device('gpu')
  device = torch.device('mps')
  # 构建模型时
  model.to(device)
  
  # 训练时
  x,y = data
  x,y = x.to(device),y.to(device)  #model和x，y要放到同一块显卡上！！！
  
  #测试时
  x,y = data
  x,y = x.to(device),y.to( device)  #model和x，y要放到同一块显卡上！！！
  ```

  ![image-20231219183251594](/Users/lifangyuan/Desktop/learn/pic/image-20231219183251594.png)

  ![image-20231219183348541](/Users/lifangyuan/Desktop/learn/pic/image-20231219183348541.png)

- 作业

  ![image-20231219183924180](/Users/lifangyuan/Desktop/learn/pic/image-20231219183924180.png)

  ```python
  # b 1 28 28
  conv2d(1,10,5,5,padding = 2)
  # b 10 28 28
  maxpooling(2)
  # b 10 14 14
  relu()
  # b 10 14 14
  conv2d(10,20,3,3)
  # b 20 12 12
  maxpooling(2)
  # b 20 6 6
  relu()
  # b 20 6 6
  conv2d(20,30,3,3,padding = 1)
  # b 30 6 6
  maxpooling(2)
  # b 30 3 3
  relu()
  # b 30 3 3
  linear(270,128)
  
  linear(128,64)
  
  linear(64,10)
  
  #这样的model非常近似于LeNet5模型（穿行的，卷积池化激活->全连接激活->分类）
  ```

  

## P*：Pytorch教程11（高级CNN）

- 卷积核 权重共享

- 之前讲的全连接网络、卷积神经网络都是串行的结构，上一层的输出是下一层的输入（串行），但是在神经网络中，网络之间还会有分支和循环。这一节我们来看一下比较复杂的神经网络结构（不是串行的），如googleNet、

- 那么复杂的网络如何实现呢？更复杂代码量越多？nonono

  有很多代码是冗余的，要想减少代码的冗余，我们可以构造函数、类（长得一样就封装成一个类呗！！然后 再把它们串起来）

- **googleNet**

  这个网络模型经常作为很多网络模型的主干，然后在此基础上进行扩充形成新的网络拿去用，如图所示，可以看到他的网络中很多结构都是相同的部分，它们叫做inception，可以把它们封装成一个函数/类，这样就减少了代码的冗余。

  总的model图：

  ![image-20231219193956175](/Users/lifangyuan/Desktop/learn/pic/image-20231219193956175.png)

  inception块内部构造图：

  ![image-20231219194335505](/Users/lifangyuan/Desktop/learn/pic/image-20231219194335505.png)

  其中，concatenate是指把张量（这里的张量形状是B * C * W * H）拼接到一块，（沿着通道的方向），如下图，因为4条路径算出来的肯定是4个张量，所以要拼接到一起，（**拼接之前要求这4个张量的宽度W和高度H是一样的，唯一可以不同的就是通道C**），像卷积3 * 3 、5 * 5 要求WH不变，那么做padding就可以了；要求 1* 1卷积核不变，那么就做带有padding的pooling就可以了。

  ![image-20231219194932284](/Users/lifangyuan/Desktop/learn/pic/image-20231219194932284.png)

  

  

  **1 * 1 卷积核有什么用呢？**用1 * 1的卷积核乘以图像C* W*H里每一个像素的值，然后就得到了卷积后的结果1 * W * H，（求过和了）这可以实现信息融合（比如说求平均、求加权平均等，那么最后的结果就包含了各个分项的信息，这叫**信息融合**），不同通道的同一位置的像素所含的信息整合到了一个块上（下图所示），与此同时还**改变了通道的数量（效率高）（不改变形状W * H）**

  ![image-20231219200450316](/Users/lifangyuan/Desktop/learn/pic/image-20231219200450316.png)

  

  那么为什么inception要做成这样？

  在构造神经网络时，有些超参数是很难选的，比如说卷积核大小kernal_size，那么googleNet在不知道哪个大小的卷积核最好用的情况下，决定把这几种卷积核的大小都用一下，然后把它们的结果叠在一起，如果将来3 * 3 卷积核比较好用，那么3 * 3 卷积核的权重就会变得很大，其他权重变小。（权重通过训练自动找到最优权重）

  

  代码：那么inception是怎么实现的？

  为了方便我们将图片旋转

  ![image-20231219201907265](/Users/lifangyuan/Desktop/learn/pic/image-20231219201907265.png)

  ![image-20231219204556520](/Users/lifangyuan/Desktop/learn/pic/image-20231219204556520.png)

  代码

  ```python
  #分支1，也叫做池化分支
  #__init__ 中
  self.branch1 = torch.nn.conv2d(in_channel,24,kernal_size=1)
  # forward中
  branch1 = F.avg_pool2d(x,kernal_size = 3,stride = 1,padding = 1)# 宽度和高度没变
  branch1 = self.branch_pool(branch1)
  
  #分支2
  #__init__ 中
  self.branch2_1 = torch.nn.conv2d(in_channel,16,kernal_size = 1)
  # forward中
  branch2 = self.branch1x1(x)
  
  #分支3
  #__init__ 中
  self.branch3_1 = torch.nn.conv2d(in_channel,16,kernal_size = 1)
  self.branch3_2 = torch.nn.conv2d(16,24,kernal_size = 5,padding = 2)
  # forward中
  branch3 = self.branch3_1(x)
  branch3 = self.branch3_2(branch3)
  
  #分支4
  #__init__ 中
  self.branch4_1 = torch.nn.conv2d(in_channel,16,kernal_size = 1)
  self.branch4_2 = torch.nn.conv2d(16,24,kennal_size = 3,padding = 1)
  self.branch4_3 = torch.nn.conv2d(24,24,kennal_size = 3,padding = 1)
  # forward中
  branch4 = self.branch4_1(x)
  branch4 = self.branch4_2(branch4)
  branch4 = self.branch4_3(branch4)
  
  # 这4个分支里面的B * C * W * H 只有C不一样，其他的B、W、H都是一样的
  
  # 最后将四个分支按照通道来拼接(forward)
  outputs = [branch1,branch2,branch3,branch4]
  return torch.cat(outputs,dim=1)# 最后的通道数为24+16+24+24 = 88
  ```

  ![image-20231219205018683](/Users/lifangyuan/Desktop/learn/pic/image-20231219205018683.png)

  ![image-20231219205421027](/Users/lifangyuan/Desktop/learn/pic/image-20231219205421027.png)

  

- **recvNet**（残差结构块网络）

  里面提到一个问题，如果把3 * 3的卷积不停的堆下去，性能会不会变好？（不会，有一个合适的个数，发生了梯度消失），那么recvNet提出了如何应对梯度消失。加入了跳链接

  

  跳链接是什么？

  在经过两个层后，**先不激活，先将它与x相加，相加后再激活**（梯度不会消失了，最小也是1）（**相加要求B * C * W * H，其中的通道宽度高度，C、W、H都得一样**）

  ![image-20231219213614422](/Users/lifangyuan/Desktop/learn/pic/image-20231219213614422.png)

  梯度不会消失的原因：梯度最小为1 不会到0

  ![image-20231219213741167](/Users/lifangyuan/Desktop/learn/pic/image-20231219213741167.png)

  论文中recvNet的结构

  ![image-20231219214011244](/Users/lifangyuan/Desktop/learn/pic/image-20231219214011244.png)

  实践一下，代码

  

  ![image-20231219214531222](/Users/lifangyuan/Desktop/learn/pic/image-20231219214531222.png)

  ```python
  class ResidualBlock(torch.nn.Module):
    # 卷积激活、卷积、recv、xy相加、激活
    def __init__(self,in_channal):
      #输出和输入的通道、宽度、高度一样
      super(ResidualBlock,self).__init__()
      self.conv1 = torch.nn.conv2d(in_channal,in_channal,kernal_size = 3,padding = 1)
      self.conv1 = torch.nn.conv2d(in_channal,in_channal,kernal_size = 3,padding = 1)
      
    def forward(self,x):
      y = F.relu(self.conv1(x))
      y = self.conv2(x)
      y = F.relu(x+y)
      return y
  ```

  结构：卷积池化激活、residualBlock、卷积池化激活、residualBlock、全连接层

  ![image-20231219214406006](/Users/lifangyuan/Desktop/learn/pic/image-20231219214406006.png)

  ```
  
  ```

  

- 心得：遇到比较复杂的网络结构时，要学会封装，用新的class类来封装它，在自己的model里面调用它；过程中的形状要提前算好

- **学习路线**

  - 学习理论（深度学习花书）
  - 阅读pytorch文档（通读一次）
  - 复现经典之作（下载代码，跑通，读代码，写关键部分的代码）
  - 选定一个研究领域，读很多论文，看他们的研究方法，扩充视野（积累不了解的方法）

- 

## P*：Pytorch教程12（基础RNN）

- 最开始讲的线性网络中有Dense/Deep neuron network （DNN）稠密网络，使用的都是全连接，线性网络，层数比较多，每层神经元比较多。（相比于其他神经网络，如CNN，全连接的权重是最多的，计算是最复杂的）

- **RNN专门用来处理序列数据**，同时也有权重共享。其中处理序列数据指的是RNN会考虑各个输入数据在时间序列上面的关系，x2这个数据会依赖于x1，x3这个数据会依赖于x2，即下一天的天气状况会部分依赖于前一天的天气状况。

- RNN通常用来处理天气、股市、金融数据、自然语言处理NLP等

- RNN是什么

  RNN cell如下图，其中Xt是序列当中时刻t所对应的数据，而Ht是Xt经过RNNcell后输出的值，它的维度可能会发生变化；RNNcell的本质是线性层（数据映射到另外的空间中）；通俗点，X1、X2、X3、...、Xn是一个样本输入的特征，（每个特征之间是有关系的，即x是序列数据），输入到RNNcell里面（本质是线性层linear），得到输出hidden1、hidden2、hidden3、...、hiddenn，而这个输出值除了依赖于这个时刻的输入值Xt，还依赖于Xt-1（Xt-1的信息通过RNNcell后，产生一个信息，这个信息刚刚好就是hidden t-1，它又会与xt一起作为hidden t的输入），而h0可以来自于CNN+全连接网络（图像+文本序列数字处理一般都这么做），也可以自己设定初始值（一般设定为0向量，但是记得这个h0维度要和后面输出的h1、h2、h3维度一样），

  

  那RNNcell和我们平时说的线性层有什么不一样的地方呢？

  RNNcell的线性层是共享的，这里的RNNcell是同一个！！所以只有一个权重，反复更新

   

  RNNcell过程图：

  ![image-20231220101646755](/Users/lifangyuan/Desktop/learn/pic/image-20231220101646755.png)

  ![image-20231220102050035](/Users/lifangyuan/Desktop/learn/pic/image-20231220102050035.png)

- RNNcell的具体计算过程：

  - Xt（input_size * 1）作为输入，通过w * Xt + b变换到hidden t‘ （hidden_size * 1）（其中w维度：hidden_size * input_size），hidden t-1作为输入，通过 w * hidden t-1 * b 变换到hidden t'' （hidden_size * 1），（其中w维度：hidden size * hidden_size） ，然后计算hidden t（两者相加再激活，RNN中激活一般用tanh），hidden t = tanh（hidden t' + hidden t''）, 其中input_size 是输入数据的条数（样本数）

    ![image-20231220103043275](/Users/lifangyuan/Desktop/learn/pic/image-20231220103043275.png)

    化简后等于：

    ![image-20231220103350930](/Users/lifangyuan/Desktop/learn/pic/image-20231220103350930.png)

   

- 代码构造一个RNNCell

  ```python
  # init
  cell = torch.nn.RNNCell(input_size = input_size,hidden_size = hidden_size)
  
  # forward
  hidden = cell(input,hidden)
  #其中input要求的维度是：batch * input_size
  #不管哪个时刻的hidden，要求的维度都是 :batch * hidden_size
  ```

- 输入一个序列到RNNCell里面，那么数据集摆放得是 seq_len * B * input_size，即特征量 * 批量值 * 每个特征是几维的 

  ![image-20231220104446468](/Users/lifangyuan/Desktop/learn/pic/image-20231220104446468.png)

- 各个变量维度概览

  输入到RNNCell中的数据x：batch_size * input_size

  RNNCell的输出数据hidden：batch_size * hidden_size

  总的数据集Dataset：seq_size * batch_size * input_size

  设计的RNNCell：torch.nn.RNNCell(input_size,hidden_size)

  ![image-20231220105623326](/Users/lifangyuan/Desktop/learn/pic/image-20231220105623326.png)

  

- **那么怎么使用RNN呢？**

  ```python
  #init
  cell = torch.nn.RNN(input_size = input_size,hidden_size = hidden_size,num_layers = num_layers)# num_layers 表示有多少层RNNcell,层的理解如下面注释所示
  '''
    y1  y2  y3  y4 ... yn
  	    ............
    h1' h2' h3' h4'... hn'
    |   |   |   |  ... | 
  h0'->   RNNcell 2   ->hn'
    |   |   |   |  ... | 
    h1  h2  h3  h4 ... hn
    |   |   |   |  ... | 
  h0 ->   RNNcell 1   ->hn
    |   |   |   |  ... | 
    x1 x2  x3  x4 ... xn
  '''
  #forward
  output,hiddenn = self.cell(input,hidden0)
  #其中input就是x1、x2、x3、...、xn，输入的时候我们把整个所有的序列给他送进去，它的维度为seqsize * batch_size * input_size
  # hidden0 就是 h0,h0',h0''... ，初始的单个隐层输入,它的维度是 numlayers * batch_size * hidden_size
  # output 就是y1、y2、y3、...、yn，它的维度是seqsize * batch_size * hidden_size
  # hiddenn 就是hn,hn',hn''... ,它的维度是 numlayers * batch_size * hidden_size
  
  
  # 它们瓜分了矩阵的四个边
  '''
  								output
              |-------------|
   hidden0    |							|  hideenn
              |							|
              |-------------|
  	  						 input
  '''
  
  # 也就是说我们如果想使用RNN，需要确定5个量：seq_size,batch_size,input_size,hidden_size,layer_nums
  ```

- torch.nn.RNN参数

  除了input_size,hidden_size,num_layers，还有batch_first

  - batch_first = True表示forward时，x数据是 batch_size * seq_size *input_size这样的，在执行时，x会自动变成 seq_size * batch_size *input_size

- 实际的小例子

  - 比如说我们要让学习器学习字符串“hello”向“ohlol”转变的规律

    ![image-20231220113625716](/Users/lifangyuan/Desktop/learn/pic/image-20231220113625716.png)

  - 1.字符向量化表示（独热向量），将独热向量送到RNN里面作为输入

    ![image-20231220114756212](/Users/lifangyuan/Desktop/learn/pic/image-20231220114756212.png)

    inputs_size = 4

    seq_size = 5

  - 2.输入到RNN里面，输出值y1、y2、y3、y4、y5，那么可以把每一个输出值yi看作是一个多分类器，（h、e、l、o里面4选1），将来每个yi输出值都是4维向量，它表示是h、e、l、o的概率，然后我们拿这4个向量接一个softmax，与y的独热向量对接即可

    ![image-20231220122249414](/Users/lifangyuan/Desktop/learn/pic/image-20231220122249414.png)

    注意这里的RNNcell输出值，outputsize是4

  - 3.代码(RNNCell)

    ```python
    import torch
    
    seq_size = 5   # 一个样本的特征数量
    input_size = 4  # 每个特征由input_size * 1的向量来表示 
    batch_size = 1  # 样本数量
    hidden_size = 4 # 输出值的每个yi都要4分类
    
    # 准备数据
    idx2char = ['e','h','l','o'] # 索引列表，便于从数字复原成字符
    x_data = [1,0,2,2,3] #'hello'
    y_data = [3,1,2,3,2] #'ohlol'  #多分类要将输出变成longTensor类型
    
    one_hot_lookup = [
      [1,0,0,0]
      [0,1,0,0]
      [0,0,1,0]
      [0,0,0,1]
    ] # 独热向量转化辅助变量
    
    x_one_hot = [one_hot_lookup[x] for x in x_data] # 构造x的独热向量,此时为 seq_size * input_size,下面要变化成seq_size * batch_size * input_size
    # y应该为seq_size *batch_size * 1 -> (seq_size *batch_size) * 1
    
    inputs = torch.Tensor(x_one_hot).view(-1,batch_size,input_size)
    labels = torch.LongTensor(y_data).view(-1，1)
    
    #构建模型 RNNcell版的,不包括seq_size
    class Model(torch.nn.Module):
      def __init__(self,input_size,hidden_size,batch_size):
        super(Model,self).__init__()
        self.input_size = input_size
        self.hidden_size = hidden_size
        self.batch_size = batch_size
        self.Rnncell = torch.nn.RNNCell(input_size = self.input_size,hidden_size = self.hidden_size)
      def forward(self,x,hidden0):
        hidden = self.Rnncell(x,hidden0)
        return hidden
      
      #生成默认的h0
      def init_hidden(self):
        return torch.zeros(self.batch_size,self.hidden_size)
        
    
    model = Model(input_size,hidden_size,batch_size)
    
    # 构建损失函数、优化器
    criterion = torch.nn.CrossEntropyLoss()
    optimizer = torch.optim.Adam(model.parameters(),lr = 0.1)
    
    #迭代训练 输入数据x是seq_size * batch_size * input_size的，所以对x进行迭代即对它的特征进行遍历，一次遍历得到的所有loss要相加
    for epoch in range(15):
      loss = 0
      hidden0 = model.init_hidden()
      optimizer.zero_grad()
      
      # 一次训练 loss要叠加
      for x_feature,y_feature in zip(x,y):
        hidden = model(x_feature,hidden0)
        loss += criterion(hidden,y_feature)
        _,y_featurn_pred_id = hidden.max(dim = 1)
        print(idx2char[,y_featurn_pred_id])
      
      loss.backward()
      optimizer.step()
      print(epoch+1,loss.item)
        
        
    ```

    ![image-20231220132906626](/Users/lifangyuan/Desktop/learn/pic/image-20231220132906626.png)

    

  - 代码（RNN）

    ```python
    # 数据准备
    import torch
    
    seq_size = 5   # 一个样本的特征数量
    input_size = 4  # 每个特征由input_size * 1的向量来表示 
    batch_size = 1  # 样本数量
    hidden_size = 4 # 输出值的每个yi都要4分类
    
    # 准备数据
    idx2char = ['e','h','l','o'] # 索引列表，便于从数字复原成字符
    x_data = [1,0,2,2,3] #'hello'
    y_data = [3,1,2,3,2] #'ohlol'  #多分类要将输出变成longTensor类型
    
    one_hot_lookup = [
      [1,0,0,0]
      [0,1,0,0]
      [0,0,1,0]
      [0,0,0,1]
    ] # 独热向量转化辅助变量
    
    x_one_hot = [one_hot_lookup[x] for x in x_data] # 构造x的独热向量,此时为 seq_size * input_size,下面要变化成seq_size * batch_size * input_size
    # y应该为(seq_size *batch_size) * 1
    
    inputs = torch.Tensor(x_one_hot).view(-1,batch_size,input_size)
    labels = torch.LongTensor(y_data)
    
    
    #构建模型
    class Model(torch.nn.Module):
      def __init__(input_size,hidden_size,batch_size,num_layers = 1):
        super(Model,self).__init__()
        self.input_size = input_size
        self.hidden_size = hidden_size
        self.batch_size = batch_size
        self.num_layers = num_layers
        self.rnn = torch.nn.RNN(input_size = self.input_size,self.hidden_size = hidden_size,num_layers = self.num_layers)
        
        def forward(self,x):
          hidden0 = torch.zeros(self.num_layers,self.batch_size,self.hidden_size)
          out,hiddenn = self.rnn(x,hidden0)
          return out.view(-1,self.hidden_size)# 变换y_pred 为 （seq_sie * batch_size） * hidden_size ,对应的y为(seq_size *batch_size) * 1
        
    
    
    
    criterion = torch.nn.CrossEntropyLoss()
    oprimizer = torch.optim.Adam(model.parameters(),lr = 0.05)
    #训练迭代
    for epoch in range(15):
      optimizer.zero_grad()
      outputs = model(inputs)
      loss = criterion(outputs,label)
      loss.backward()
      oprimizer.step()
      
      _,idx = outputs.max(dim = 1)
      idx = idx.data.numpy()
      print('predict:'join([idx2char[x] for x in idx]))
      print(epoch+1,loss.item())
    ```

    

  

- 总结一下RNNCell和RNN的区别

  - model的init函数中，RNNCell只需要input_size、hidden_size；RNN需要input_size、hidden_size、num_layers

  - model的forward函数中，RNNCell需要输入x和hidden0，输出out；RNN需要输入x和hidden0，输出out和hiddenn；且这两者输入输出数据的维度也是不一样的

  - RNNCell和RNN输入输出数据的维度对比：

    RNNCell输入x，要求维度：batch_size * input_size

    RNNCell输入hidden0，要求维度：batch_size * hidden_size

    RNNCell输出out，维度：batch_size * hidden_size

    

    RNN输入x，要求维度：seq_size * batch_size * input_size

    RNN输入hidden0，要求维度：num_layers * batch_size * hidden_size

    RNN输出out，维度：seq_size * batch_size * hidden_size

    RNN输出hidden，维度：num_layers * batch_size * hidden_size

  - 在准备mini-batch数据x_data、y_data方面是一样的，但view是不一样的：

    RNNCell的x_data，维度：seq_size * batch_size * input_size

    RNNCell的y_data，维度：seq_size * batch_size * 1

    RNNCell的x_data.view(seq_size,batch_size,input_size)

    RNNCell的y_data.view(seq_size ,batch_size ,1)

    (这里RNNCell的y_data.view原因是，在训练迭代时，需要循环遍历特征(x_data和y_data，生成x i 和 y i)，seq_size，所以模型输出的y_pred i维度是batch_size * hidden_size，那么y i对应的维度应该是batch_size * 1 (*1一般都要省去的))

    

    RNN的x_data，维度：seq_size * batch_size * input_size

    RNN的y_data，维度：seq_size * batch_size * 1

    RNN的x_data.view(seq_size,batch_size,input_size)

    RNN的y_data.view(seq_size * batch_size ,1)

    (这里RNN的y_data.view原因是，在训练迭代时，不需要循环遍历特征，而是直接通过模型处理，在模型中我们将输出的y_pred维度变成了 (seq_size * batch_size) , hidden_size 所以我们对应的y_data的维度应该是 (seq_size * batch_size) , 1

  - 在训练迭代时，RNNCell需要手动的迭代每个特征，将损失求和，迭代所有特征完成后，才算是完成了一次前向运算，然后才可以反向，更新权重（表现为loss += criterion(y_pred,y)，注意这里是构建网络，所以不用.item()）；而RNN中不需要手动迭代每个特征，这个过程已经在模型中完成了，那么我们就直接像往常一样前向、后向、更新。

- 数据处理除了独热向量还有嵌入层？

  - 独热向量的缺点：维数太多了，字母也就罢了，如果是词、汉字那就太多了；矩阵过于稀疏；硬编码的
  - 一般更常用的是embedding(嵌入层)；embedding就是说我们把一个高维的稀疏的样本映射到一个稠密的低维的空间里面，就是常说的数据降维。我们依托于矩阵进行映射就可以了，比如说4维数据到5维数据，我们只需要构建一个5 * 4 的矩阵

- 改善结构：

  ![image-20231220152337290](/Users/lifangyuan/Desktop/learn/pic/image-20231220152337290.png)

  那么怎么写embedding层？

   embedding进行初始化需要参数num_embeddings（输入的独热向量是几维的）；embedding_dim（每个embedding向量的大小），这两个构成了embedding向量的高度和宽度；输入要求：longTensor类型的值，输出：输入的维度 * embedding （如输入是是seq_size * batch_size 那么输出的就是seq_size * batch_size * embedding）

  

- 改善代码(model)

  ```python
  num_class =4
  input_size = 4
  hidden_size = 8
  embedding_size = 10
  num_layers = 2
  batch_size = 1
  seq_size = 5
  
  idxchar = ['e','h','l','o']
  x_data = [[1,0,2,2,3]]
  y_data = [3,1,2,3,2]
  inputs = torch.longTensor(x_data) #维度batch_size * seqlen
  labels = torch.longTensor(y_data) #维度batch_size * seqlen
  
  class Model(torch.nn.Module):
    def __init__(self):
      super(Model,self).__init__()
      self.emb = torch.nn.Embedding(input_size,embedding_size)
      self.rnn = torch.nn.RNN(input_size=embedding_size,hidden_size = hidden_size,num_layers= num_layers,batch_size = True)
      self.fc = torch.nn.Linear (hidden_size,num_class)
      
    def forward(self,x):
      hidden = torch.zeros(num_layers,x.size(0),hidden_size)
      x = self.emb(x)
      x = self.rnn(x,hidden)
      x = self.fc(x)
      return x.view(-1,num_class)
    
  # 后面损失函数、优化器和迭代训练和RNN+独热一样
  ```

  

- LSTM（性能比RNN好得多，但是时间复杂度比较高）

  输入是x,h0，c0

  输出是y,hn，cn

  ![image-20231220185237075](/Users/lifangyuan/Desktop/learn/pic/image-20231220185237075.png)

  - __ init __中

    ```python
    self.lstm = torch.nn.LSTM(input_size,output_size,num_layers,bidirectional)
    #bidirectional如果是True是双向LSTM，否则为单向，默认为False
    ```

  - forward中

    ```python
    output,(hn,cn) = self.lstm(input,(h0,c0))
    #其中input是输入数据，必须是tensor，它的维度为：seq_size,batch_size,input_size
    #h0是初始隐藏层，必须是tensor，它的维度：(num_layers * num_directions),batch_size,hidden_size
    #c0是初始细胞状态，必须是tensor,它的维度:(num_layers * num_directions),batch_size,hidden_size
    
    #其中num_direction有两种选择，如果为1代表LSTM单向即bidirectional = False，如果为2代表LSTM双向，即bidirectional = True
    
    #output 是保存RNN最后一层输出的tensor ，维度:seq_size , batch_size , hidden_size * num_directions
    #hn是保存RNN最后一个时间步隐藏状态的tensor 维度:num_layers*num_directions,batch_size,hidden_size
    #cn是保存RNN最后一个时间步细胞状态的tensor 维度:num_layers*num_directions,batch_size,hidden_size
    ```

    

- GRU（比RNN性能好，比LSTM运算时间少）

  输入是x，h0

  输出是y，hn

  - init中

    ```python
    self.gru = torch.nn.GRU(input_size,hidden_size,num_layers,bidirectional)
    #bidirectional如果是True是双向GRU，否则为单向，默认为False
    ```

  - forward中

    ```python
    output,hn = self.gru(input,h0)
    #其中input是输入数据，必须是tensor，维度：seq_size,batch_size,input_size
    #h0是隐藏层的初始状态，必须是tensor,维度：num_layers * num_directions,batch_size,hidden_size
    
    #output是输出，是tensor，维度：seq_size , batch_size , hidden_size * num_directions
    # hn是保存RNN最后一个时间步隐藏状态的tensor，维度：num_layers * num_directions,batch_size,hidden_size
    ```

    

## P*：Pytorch教程13（高级RNN）

- 这一节主要讲RNN应用，如何实现一个循环神经网络的分类器，案例：名字分类，输入数据：姓名（几千个），输出数据：名字所属国家（18种）。

- RNN可以加入ATT注意力机制

- 步骤：

  1. 把字/词变成一个ont-hot向量或者输入到嵌入层，那么问题来了：各个名字的长度不一样怎么办？换句话说，一个名字的长度就是该样本的特征数，**如何处理样本特征数不一样**？

  2. 经过循环神经网络RNN

  3. 输入全连接网络（由于RNN输出不一定和分类的数量一样，所以利用全连接网络将RNN输出进行映射）

  4. 网络图：

     ![image-20231220205638802](/Users/lifangyuan/Desktop/learn/pic/image-20231220205638802.png)

     

     ![image-20231220205705550](/Users/lifangyuan/Desktop/learn/pic/image-20231220205705550.png)

- 代码

  ```python
  import torch
  
  
  #0. 常量设置
  HIDDEN_SIZE = 100
  NUM_LAYERS = 2
  BATCH_SIZE = 256
  N_EPOCH = 100
  N_CHARS = 128
  USE_GPU = False
  
  #1.准备数据
  '''
  	拿到的都是一些字符串，第一件事就是把它转变成一个二维矩阵（matrix[i][j]表示第i个名字里面的第j个字符）；
  	第二件事情是做词典，词典对于字符集来说是比较好做的，用ascii码表来作为它的词典（ascii码0-127一共有128个字符，我们把字典长度N_CHARS设置为128），然后求矩阵matrix中每一个字符对应的ascii码值，此时matrix变成了[[77,97,99,108,101,97,110],[86,97,106,110,105,99,104,121],...],（需要注意的是这里的存储的值对应的是一个独热向量，比如77表示一个独热向量，这个独热向量有128行1列，除了第77行为1，其余行都为0），但是对于embedding来说，你只需要告诉它第几个维度是1就可以了，即对于一个名字我们拿到[77,97,99,108,101,97,110]就可以啦！！
  	第三个问题就是各个名字不一样长，所以我们要做一个padding，缺失的地方我们补充值0，补成一样的长度，这样才能构成张量
  	第四个问题是关于输出值——国家，我们要把国家字符串转成一个分类的索引，一个国家代表一个数字，做成国家字典，便于查找
  	
  	需要注意的是，这个数据集没有现成的，需要我们自己构造，datasets，dataloader
  
  '''
  class NameDataset(Dataset):
    def __init__(self,is_train_set = True):
      filename = 'train.csv.gz' if is_train_set else 'test.csv.gz'
      with gzip.open(filename,'rt') as f:
        reader = csv.reader(f)
        rows = list(reader)
        
      self.names = [row[0]for row in rows]  # 名字列表 字符串
      self.countries = [row[1] for row in rows]  # 国家列表 字符串
      self.len = len(self.names)
      self.countrt_list = list(sorted(set(self.countries)))
      # 将列表转成词典
      self.country_dict = self.getCountryDict()
      self.country_num = len(self.country_list)
      
    def __getitem(self,index):
      return self.names[index],self.country_dict[self.countries[index]]
    def __len__(self):
      return self.len
    
    def getCountryDict():
      country_dict = dict()
      for index,country_name in enumerate(self.country_list):
        country_dict[country_name] = index
      return country_dic
    
    def idx2country(self,index):
      return self.country_list[index]
   	def getCountriesNum(self):
      return self.country_num
    
  train_dataset = NameDataset(True)
  test_dataset = NameDataset(False)
  train_loader = dataloader(train_dataset,batch_size = BATCH_SIZE,shuffle=True)
  test_loader = dataloader(test_dataset,batch_size = BATCH_SIZE,shuffle=False)
  
  N_COUNTRY = train_dataset.getCountriesNum()
  
  # 名字列表 字符串 to tensor(变换到了batch , seq，矩阵！！)
  def make_tensors(names,countries):
    # 将名字列表里面的每个名字都分开成单个的字符，并且转换为ascii码列表
    '''
    	def name2list(name):
    		arr = [ord(c)for c in name]
    		return arr,len(arr)
    '''
    sequences_and_lengths = [name2List(name)for name in names] # 每个名字，arr，len
    name_sequence = [s1[0]for s1 in sequences_and_lengths]
    seq_lengths = torch.longTensor([s1[1]for s1 in sequences_and_lengths])
    
    countries = countries.long() # 记得处理成long类型
    
    # 做padding，原理是先创建一个矩阵，然后把相应的数据拷贝过来
    seq_tensor = torch.zeros(len(name_sequence),seq_lengths.max()).long()
    for idx,(seq,seq_len) in enumerate(zip(name_sequences,seq_lengths)):
      seq_tensor[idx,:seq_len] = torch.LongTensor(seq)
    
    
    # 排序,按照序列的长度进行排序,由大到小，返回排好序的序列和ids
    seq_lengths,perm_idx = seq_lengths.sort(dim = 0,descending = True)
    seq_tensor = seq_tensor[perm_idx]
    countries = conutries[perm_idx]
    
    return create_tensor(seq_tensor),create_tensor(seq)lengths,create_tensor(countries)
  '''
  	def create_tensor:
  		#用device去跑
  		if USE_GPU:
  			device = torch.device('mps')
  			tensor = tensor.to(device)
  		return tensor
  '''
    
    
  
  
  
  
  
  #2.构建模型
  class RNNClassifier(torch.nn.Module):
    def __init__(self,input_size,hidden_size,output_size,num_layers,direction = 1):
      # output_size 就是 num_class
      super(RNNClassifier).__init()
      self.hidden_size = hidden_size
      self.num_layers = num_layers
      self.n_direction = direction
      
      self.embedding = torch.nn.Embedding(input_size,hidden_size)
      self.gru = torch.nn.GRU(hidden_size,hidden_size,num_layers,bidirectional)
      self.fc = torch.nn.Linear(hidden_size * n_direction,output_size)
    
    
    def forward(self,x,seq_lengths):
      hidden0 = torch.zero(self.n_layers * self.direction,batch_size,self.hidden_size)
      input = input.t()  # 转置input batch_size * seq_size -> seq_size * batch_size
      batch_size = input.size(1)
      x = self.embedding(x)
      
      # 发现每个名字列表里面有很多0，为了提高计算效率，我们将它排序，需要两个变量：input和各个名字的长度列表，如何将input按照每个名字的有效长度（统一的长度（特征数）减去补充的0）进行降序排序？：用pack_padded_sequence ，第一个参数tensor，维度要求：seq , batch , hidden_size,,且已经降序排好了！！！！自己排，第二个参数要求是longtensor，维度要求：
      gru_input = pack_padded_sequence(embedding,seq_lengths)
      
      output,hn = self.gru(gru_input,hidden0)
      
      # 双向的话 hn和hn‘要拼接，单向的话，hn就可以了
      if self.n_direction == 2:
        hidden_cat = torch.cat(hn[-1],hn[-2],dim = 1)
      else:
        hidden_cat = hn[-1]
      
      fc_output = self.fc(hidden_cat)
      return fc_output
        
      
  # 训练迭代
  def train():
    total_loss = 0
    for i,(name,countries) in enumerate(trainloader):
      inputs,seq_lengths,target = make_tensors(names,countries)
      output = classifier(inputs,seq_lengths)
      loss = criterion(output,target)
      optimizer.zero_grad()
      loss.backward()
      optimizer.step()
      
      total_loss += loss.item()
  
      return total_loss
      
  # 测试迭代
  def test():
    correct = 0
    total = len(testset)
    with torch.no_grad():
      for i,(names,countries) in enumerate(testloader):
        inputs,seq_lengths,target = make_tensors(names,countries)
        output = classifier(inputs,seq_lengths)
        pred = output.max(dim = 1,keepdim = True)[1]  # 
        correct += pred.eq(target.view_as(pred)).sum().item()
        
        percent = correct / total
        print(percent)
        
        return percent
  
  
  
  # 主函数
  if __name__ == '__main__':
    classifier = RNNClassifier(N_CHARS,HIDDEN_SIZE,N_COUNTRY,N_LAYER)
    '''
    		其中N_CHARS 是指 字母表的大小，每一个字符是英文字母，每一个字符都会转换成一个独热向量，那么字母表一共有多少个元素就是N_CHARS
    		HIDDEN_SIZE 是指 隐层的维度
    		N_COUNTRY 是指 国家类别数
    		N_LAYER 是指 RNN的层数
    '''
    
    if USE_GPU:
      device = torch.device('cuda:0')
      classifier.to(divice)
      
     
    criterion = torch.nn.CrossEntropyLoss()
    optimizer = torch.optim.Adam(model.parameters(),lr = 0.001)
    
    #想打印训练时间有多长：
    start = time.time()
    '''
    	计算一下，训练了多长时间
    	def time_since(since):
    		s = time.time() - since
    		m = math.floor(s / 60)
    		s -= m * 60
    		return ('%dm % ds' % (m,s))
    '''
    acc_list = []
   	for epoch in range(100):
      train()
      acc = test()
      acc_list.append(acc)
  ```

  

- 深度学习做古诗：

  - 首先需要大量古诗的数据集

  - 把古诗中所有的字找出来，建立一个词典，如（山：23，水：95），古诗数据集中一共有多少个字我们的词典就有多少条记录

  - 输入嵌入层

  - 再，输入rnn，要求： 比如说何日平胡虏，我们输入何到rnn和fc中，要求输出日；输入日到rnn和fc中，要求输出平；输入平到rnn和fc中，要求输出胡；输入胡到rnn和fc中，要求输出虏；如图所示。那么假设词典中一共有4000个记录，那么一个字对应的输出就有4000个，4000个里面每一个输出代表作为下一个输出的概率。

    ![image-20231221111555332](/Users/lifangyuan/Desktop/learn/pic/image-20231221111555332.png)

  - 怎么运作呢（test）？当我们向这个模型中随便输入一个字w0的时候，模型输出下一个字w1（w1是w0输出值中概率最大的字），再把w1作为输入，模型输出w2（w2是w1输出值中概率最大的字）...这样就可以做出一首诗了；

  - 但是你会发现，如果每次都选择前一个字的输出概率最大的值作为下一个字的话，那么结果太过于单一（我输入100次水，做出来的诗都是一样的），此时就可以引入随机数，用轮盘赌机制（如果w0作为输入，其输出值4000个字里面，某个输出值较大，那么就大概率会输出这个字，但是不一定会输出这个字）来改善单一的状况；为了防止输出一些牛头不对马嘴的诗句，记得设定一些阈值

- 作业：kaggle电影评论，根据文本判断负面、正面等 5分类

## P*：Pytorch教程13